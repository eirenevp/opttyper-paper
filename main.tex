%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)

%ivp for submission add ,review,anonymous remove nonacm
\documentclass[acmsmall, review, anonymous]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}

%% Lengths
% linewidth = textwidth = 395.8225pt

% \makeatletter
% \let\@authorsaddresses\@empty
% \makeatother

%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review,anonymous]{acmart}\settopmatter{printfolios=true}

%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[sigplan]{acmart}\settopmatter{}

% Hyperref commands to improve autoref
\def\sectionautorefname{Section}
\def\subsectionautorefname{Section}
\def\subsubsectionautorefname{Section}

%% Conference information
%% Supplied to authors by publisher for camera-ready submission;
%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
% ivp for submission uncomment 26-32 lines
\acmJournal{PACMPL}
% \acmVolume{1}
% \acmNumber{CONF} % CONF = POPL or ICFP or OOPSLA
% \acmArticle{1}
% \acmYear{2018}
% \acmMonth{1}
% \acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from traditional SIGPLAN
%% proceedings format to PACMPL format must update the
%% '\documentclass' and topmatter commands above; see
%% 'acmart-pacmpl-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption
                        
                        
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphpap,amscd,mathrsfs,graphicx,lscape,dsfont,bm,url,color,bm}
\usepackage{verbatim}
\usepackage{parcolumns}
\usepackage{mathtools, cuted, IEEEtrantools}
\usepackage[capitalise,nameinlink]{cleveref}
\usepackage{bold-extra}
\usepackage{threeparttable}
\usepackage{tabularx}
\usepackage{adjustbox}
\usepackage{caption}
\usepackage{xspace}
\usepackage[inline]{enumitem}
\usepackage{bm}
\usepackage{balance}
\newcommand{\qqpi}[2]{[\![#2]\!]_{#1}}
\newcommand{\projectname}{\textsc{OptTyper}\xspace}
\newcommand\numberthis{\addtocounter{equation}{1}\tag{\theequation}}

% Restating a theorem
\newcommand{\restate}[1]{\textsc{Restatement of #1}. \hspace*{1pt} \it}

\definecolor{Maroon}{cmyk}{0.4,0.87,0.68,0.32} 
\definecolor{RoyalBlue}{rgb}{0.0,0.14,0.6}
\definecolor{mygreen}{rgb}{0.45,0.62,0.51}
\definecolor{UscGold}{rgb}{1.0,0.8,0.0}
\definecolor{mygray}{rgb}{0.35,0.35,0.35}
\definecolor{mypurple}{rgb}{0.69,0.50,0.63}
\definecolor{myrose}{rgb}{0.58,0.50,0.63}
%%%%%%%%%%% for comments %%%%%%%%%%%%%%%%%%%%%%%
\usepackage{color-edits}
% \usepackage[suppress]{color-edits}
\addauthor{ivp}{Maroon}
\addauthor{adg}{RoyalBlue}
\addauthor{cas}{mygreen}
\addauthor{ebr}{UscGold}

\newcommand{\margincomment}[2]{\marginpar{\scriptsize\color{Maroon}#1 says: #2}}
\newcommand{\adg}[1]{\margincomment{ADG}{#1}}
\newcommand{\cas}[1]{\margincomment{Charles}{#1}}
\newcommand{\etb}[1]{\margincomment{Earl}{#1}}
\newcommand{\ivp}[1]{\margincomment{IVP}{#1}}

% \ivpedit {} writes with color within the original text, if we uncomment
% suppress and comment plain color edits we will have black color

% \ivpcomment {} comments in brackets additional to the text if we use
% suppress comments are no longer visible

% \ivpdelete{} indicates that something has been deleted in case you want
% to see it again, when using suppress is no longer visible
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% JavaScript
% JavaScript support
\usepackage{listings}
\lstset{ %
backgroundcolor=\color{white}, % choose the background color; you must add \usepackage{color} or \usepackage{xcolor}
basicstyle=\scriptsize, % the size of the fonts that are used for the code
breakatwhitespace=true, % sets if automatic breaks should only happen at whitespace
breaklines=true, % sets automatic line breaking
captionpos=b, % sets the caption-position to bottom
commentstyle=\color{mygreen}, % comment style
deletekeywords={...}, % if you want to delete keywords from the given language
%escapeinside={\%}, % if you want to add LaTeX within your code
escapeinside={*@}{@*}, % if you want to add LaTeX within your code
extendedchars=true, % lets you use non-ASCII characters; for 8-bits encodings only, does not work with UTF-8
%frame=single, % adds a frame around the code
keepspaces=true, % keeps spaces in text, useful for keeping indentation of code (possibly needs columns=flexible)
columns=flexible,
keywordstyle=\color{blue}, % keyword style
morekeywords={*,...}, % if you want to add more keywords to the set
numbers=left, % where to put the line-numbers; possible values are (none, left, right)
numbersep=2pt, % how far the line-numbers are from the code
numberstyle=\tiny\color{mygray}, % the style that is used for the line-numbers
rulecolor=\color{black}, % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
showspaces=false, % show spaces everywhere adding particular underscores; it overrides 'showstringspaces'
showstringspaces=false, % underline spaces within strings only
showtabs=false, % show tabs within strings adding particular underscores
stepnumber=1, % the step between two line-numbers. If it's 1, each line will be numbered
%stringstyle=\color{mymauve}, % string literal style
tabsize=2, % sets default tabsize to 2 spaces
title=\lstname % show the filename of files included with \lstinputlisting; also try caption instead of title
}

\lstdefinelanguage{JavaScript}{
keywords={const, typeof, new, true, false, catch, function, 
  return, null, catch, switch, var, if, in, while, do, else, 
  case, break, class, export,throw, implements, import, this,
  exports, interface, readonly},
keywordstyle=\color{myrose},
ndkeywords={boolean, string, number, any, Array, Window, Event, Array<any>},
ndkeywordstyle=\color{Maroon},
identifierstyle=\color{black},
sensitive=false,
escapechar=!,
comment=[l]{//},
morecomment=[s]{/*}{*/},
commentstyle=\color{mygray}\ttfamily,
%stringstyle=\color{red}\ttfamily,
morestring=[b]',
morestring=[b]"
}
 
\newlength{\listingindent}  %declare a new length
\setlength{\listingindent}{\parindent} 

\lstset{
language=JavaScript,
extendedchars=true,
basicstyle=\ttfamily,
showstringspaces=false,
showspaces=false,
numbers=left,
numberstyle=\color{mygray}\tiny,
numbersep=1pt,
tabsize=2,
breaklines=true,
showtabs=false,
captionpos=b,
xleftmargin=\listingindent,         
framexleftmargin=\listingindent,    
framextopmargin=6pt,
framexbottommargin=6pt, 
frame=tlrb, framerule=0pt,
linewidth=\linewidth
}

\usepackage{mathrsfs}
\lstdefinelanguage{Fake}{
    keywords={function, return},
    % basicstyle=\ttfamily,
    keywordstyle=\bfseries,
    sensitive=false,
    escapechar=!,
    numbers=none
}

\graphicspath{ {figs/} }

\begin{document}

%% Title information
\title{\textsc{OptTyper}: Probabilistic Type Inference by Optimising Logical and Natural Constraints}
%\title[Short Title]{Full Title}         %% [Short Title] is optional;
%% when present, will be used in
%% header instead of Full Title.
%\titlenote{with title note}             %% \titlenote is optional;
%% can be repeated if necessary;
%% contents suppressed with 'anonymous'
%\subtitle{Subtitle}                     %% \subtitle is optional
%\subtitlenote{with subtitle note}       %% \subtitlenote is optional;
%% can be repeated if necessary;
%% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{Irene Vlassi Pandi}
%\authornote{with author1 note}          %% \authornote is optional;
%% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
	\position{Position1}
	%\department{Department1}              %% \department is recommended
	\institution{University of Edinburgh}            %% \institution is required
	%\streetaddress{Street1 Address1}
%	\city{Edinburgh}
	%\state{State1}
	%\postcode{Post-Code1}
	\country{UK}                    %% \country is recommended
}
%\email{irene.vp@ed.ac.uk}          %% \email is recommended

%% Author with single affiliation.
\author{Earl T. Barr}
%\authornote{with author1 note}          %% \authornote is optional;
%% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%	\position{Position1}
	%\department{Department1}              %% \department is recommended
	\institution{University College London}            %% \institution is required
%	\streetaddress{Street1 Address1}
%	\city{London}
%	\state{State1}
%	\postcode{Post-Code1}
	\country{UK}                    %% \country is recommended
}
%\email{e.barr@ucl.ac.uk}          %% \email is recommended

%% Author with two affiliations and emails.
\author{Andrew D. Gordon}
%\authornote{with author2 note}          %% \authornote is optional;
%% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%	\position{Position2a}
%	\department{Department2a}             %% \department is recommended
	\institution{Microsoft Research Cambridge}           %% \institution is required
%	\streetaddress{Street2a Address2a}
%	\city{Cambridge}
%	\state{State2a}
%	\postcode{Post-Code2a}
	\country{UK}                   %% \country is recommended
}
%\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
%	\position{Position2b}
%	\department{Department2b}             %% \department is recommended
	\institution{University of Edinburgh}           %% \institution is required
%	\streetaddress{Street3b Address2b}
%	\city{City2b}
%	\state{State2b}
%	\postcode{Post-Code2b}
	\country{UK}                   %% \country is recommended
}
%\email{first2.last2@inst2b.org}         %% \email is recommended

%% Author with two affiliations and emails.
\author{Charles Sutton}
%\authornote{with author2 note}          %% \authornote is optional;
%% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
%	\position{Position2a}
%	\department{Department2a}             %% \department is recommended
	\institution{Google AI}           %% \institution is required
%	\streetaddress{Street2a Address2a}
	\city{Mountain View}
	\state{CA}
%	\postcode{Post-Code2a}
	\country{USA}                   %% \country is recommended
}
%\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
%	\position{Position2b}
%	\department{Department2b}             %% \department is recommended
	\institution{University of Edinburgh}           %% \institution is required
%	\streetaddress{Street3b Address2b}
%	\city{City2b}
%	\state{State2b}
%	\postcode{Post-Code2b}
	%\country{Country2b}                   %% \country is recommended
}
%\email{csutton@inf.ed.ac.uk}
\affiliation{
%	\position{Position2c}
%	\department{Department2c}             %% \department is recommended
	\institution{The Alan Turing Institute}           %% \institution is required
%	\streetaddress{Street3c Address2c}
%	\city{City2c}
%	\state{State2c}
%	\postcode{Post-Code2c}
	\country{UK}                   %% \country is recommended
}

%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}\label{sec:abstract}
    We present a new approach to the type inference problem for dynamic languages. Our goal is to combine \emph{logical} constraints, that is, deterministic information from a type system, with \emph{natural} constraints, that is, uncertain statistical information about types learnt from sources like identifier names. To this end, we introduce a framework for probabilistic type inference that combines logic and learning: logical constraints on the types are extracted from the program, and deep learning is applied to predict types from surface-level code properties that are statistically associated, such as variable names. The foremost insight of our method is to constrain the predictions from the learning procedure to respect the logical constraints, which we achieve by relaxing the logical inference problem of type prediction into a continuous optimisation problem.
	%   We combine logical constraints generated by a static analysis of the source code with natural constraints learned from
	%   existing codebases into a single optimisation problem.
	%   %
	%   % To do so, the key idea is to use a continuous representation of the logical constraints part that can be jointly optimised with the learned natural constraints.
	%   The main insight of our method is to relax the problem of type inference into a problem of numerical continuous optimisation.
	%problem by using a continuous representation of the logical constraints part.
	
	As a proof of concept, we build a tool called \projectname to predict types for an unannotated TypeScript file.
	%
	\projectname 
	combines a continuous interpretation of logical constraints derived by a simple program transformation and static analysis of TypeScript code, with natural constraints obtained from a deep learning model, which learns naming conventions for types from a large codebase. 
	%
	By evaluating \projectname{}, we show that the combination of logical and natural constraints yields a large improvement in performance over either kind of information individually and achieves a 3\% improvement over the state-of-the-art.
	%
	% By transcribing a type inference procedure into a numerical optimisation problem we initiate a novice way to balance between hard and natural constraints for suggesting types and therefore contribute towards situations where developers efficiently achieve the best of both the dynamically and statically-typed world.
\end{abstract}

\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007</concept_id>
<concept_desc>Software and its engineering</concept_desc>
<concept_significance>500</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering}


%% Keywords
%% comma separated list
\keywords{Type Inference, Dynamic Languages, Continuous
	Relaxation, Numerical optimisation, Deep Learning, TypeScript}
%% \keywords are mandatory in final camera-ready submission

\maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\section{Introduction}
Statically-typed programming languages aim to enforce correctness and safety properties
on programs by guaranteeing constraints on program behaviour.
A large scale user-study
suggests that programmers
benefit from type safety~\citep{hanenberg14}; use of type has also been
shown to prevent field bugs~\citep{gao17}.
However, type safety comes at a cost: these languages often require explicit type annotations,
which imposes the burden of declaring and maintaining these annotations on the programmer.
Strongly statically-typed, usually functional languages, like Haskell or ML,
offer type inference procedures that reduce
the cost of explicitly writing types but come with
a steep learning curve~\citep{tirronen15}.

Dynamically typed languages, which either lack or do not require type
annotations, are relatively more popular~\cite{meyerovich12}.  Initially
designed for quick and dirty scripting or rapid prototyping, these languages
have begun reaching the limits of what can be achieved without the help of type
annotations, as witnessed by the heavy industrial investment in and proliferation of static type systems for these languages (TypeScript~\cite{typescript} and Flow~\cite{flow} are just two
examples).
Retrofit for dynamic languages, these type systems include gradual~\cite{siek06}
and optional type systems~\citep{bracha2004pluggable}.  Like classical type systems, these type systems
require annotations to provide benefits.  Hence, reducing the annotation type tax
for dynamic languages remains an open research topic.

\subsection{Probabilistic Type Inference}
Probabilistic type inference
has recently been proposed as an attempt to reduce the burden
of writing and maintaining type
annotations~\cite{wei20,raychev15,hellendoorn18}.
Just as the availability of large data sets has transformed artificial intelligence,
the increased volume of publicly available source code, through
code repositories like GitHub\footnote{\href{https://github.com}{https://github.com}}
or GitLab\footnote{\href{https://gitlab.com}{https://gitlab.com}},
enables a new class of applications that leverage statistical
patterns in large codebases~\cite{allamanis17}.
Specifically, for type inference, machine learning
allows us to develop less strict type inference systems
that learn to predict types from uncertain information,
such as comments, names, and lexical context,
even when traditional type inference procedures
fail to infer a useful type.

The classic literature on conventional type systems takes great care to demonstrate
that type inference only suggests sound types~\cite{DBLP:journals/jcss/Milner78,Pierce2002}.
Probabilistic type inference takes a different perspective:
a tool for probabilistic type inference usefully reduces the human annotation burden
as long as it frequently makes correct predictions, even if predictions are sometimes wrong.
Hence, we evaluate probabilistic type inference with statistical metrics.

Probabilistic type inference is not in conflict with classical type inference but complements it.
There are settings, like TypeScript, where correct type inference is too imprecise.
In these settings, probabilistic type inference helps the human in the loop to move a
partially typed codebase---one lacking so many type annotations that classical type inference
can make little progress---to a sufficiently annotated state that classical type inference can take over and finish the job.
% The human in the loop can ignore incorrect or unsuitable type predictions,
% or detect them for example by classic type checkers.

Two examples of probabilistic type inference systems are JSNice~\cite{raychev15},
which uses probabilistic graphical models to statistically infer types of identifiers
in programs written in JavaScript,
and DeepTyper~\cite{hellendoorn18}, which targets TypeScript via deep learning techniques.
%see \cref{sec:related} for a more elaborate comparison to related work.
However, none explicitly models the underlying
type inference rules, and, thus, their predictions ignore useful type constraints.
%
Most recently, \citet{wei20} introduced LambdaNet to exploit both type constraints and name usage information by using graph neural networks~\citep{allamanis17}. LambdaNet, however, does not constrain 
\emph{the output} of the network to satisfy these constraints;
this must be learned automatically from data,
and there is no guarantee that the resulting model will respect the type constraints at test time. 
Indeed, in practice, we observe that LambdaNet
produces annotations that do not respect the learnt 
logical relationships (\cref{fig:LambdaNet}).

% cut, as stated almost identically in next section
%The goal in our work is to combine the strengths of machine learning for type inference, which can leverage uncertain information such as comments and names, and traditional type inference, which leverages program semantics.

\subsection{Our Contribution}

The probabilistic type inference task is special in that it makes no sense to suggest types that violate type constraints.
To respect this principle, we propose \projectname (from ``optimising for optional types''), a novel framework for probabilistic type inference that couples hard, \textit{logical} type constraints with soft constraints drawn from structural, \textit{natural} patterns into a single optimisation problem. While, in theory, there is the option of filtering out the incorrect predictions, our framework goes beyond that; our composite optimisation serves as a communication channel between the two different sources of information. 

% To do so, it relaxes
% the logical constraints, extracted at test time
% Hard means that \projectname's type suggestions obey type constraints that it extracts at test time.

Current type inference systems rely
on one of two sources of information
\begin{enumerate}[label=(\Roman*)]
	\item \emph{Logical Constraints} on type annotations that follow from the type system.
	      These are the constraints used by standard deterministic approaches for static type inference.
	\item \emph{Natural Constraints} are statistical constraints on type annotations
	      that can be inferred from relationships between types and surface-level properties such as names and lexical context.
	      These constraints can be learned by applying machine learning to large codebases.
	      They are the constraints that are employed by probabilistic typing systems like JSNice and DeepTyper.
\end{enumerate}
Our goal is to improve the accuracy of probabilistic type
inference by combining both kinds of constraints into a single analysis, unifying logic and learning into a single framework.
We start with a formula that defines the logical constraints on the types of a set of identifiers in the program,
and a machine learning model, such as a deep neural network, that probabilistically predicts the type of each identifier.

The key idea behind our methods is a
\emph{continuous relaxation} of
the logical constraints \cite{hajek98}.
This means that  we relax the logical formula into a continuous function by relaxing type environments
to probability matrices and defining
a continuous semantic interpretation of logical expressions.
The relaxation has a special property, namely,
that when this continuous function is maximised with respect
to the relaxed type environment, we obtain a discrete type environment
that satisfies the original constraints.
The benefit of this relaxation is that logical constraints
can now be combined with the probabilistic
predictions of type assignments that are
produced by machine learning methods.
More specifically, this allows us to define a continuous function over the continuous version of the type environment
that sums the logical and natural constraints.
And once we have a continuous function, we can optimise it:
we set up an optimisation problem that returns the most natural type assignment for a
program, while at the same time respecting type constraints produced by traditional type inference.

Our main contributions follow:
\begin{itemize}[label=\raisebox{0.25ex}{\tiny$\bullet$}]
	\item We introduce a general, principled framework that uses soft logic to combine logical and natural constraints for type inference,
	      based on transforming a type inference procedure into a numerical optimisation problem.
	\item We instantiate this framework in \projectname, a probabilistic type inference tool for TypeScript.
	\item We evaluate \projectname and find that combining logical and natural constraints has better performance than either alone. Further, \projectname outperforms state-of-the-art systems,
	      LambdaNet, DeepTyper and JSNice.
	\item We show how \projectname achieves its high performance by combining logical and natural constraints at test time; to the best of our knowledge, it is the first tool for probabilistic type inference to do so.
\end{itemize}

% \subsection{Our Framework via an Example}
% Before formalizing our framework, we pictorially illustrate our approach in \cref{fig:fullexample}.
%
\section{General Framework for Probabilistic Type Inference} \label{sec:framework}
\begin{figure}[!t]
    \centering
    \def\svgwidth{\linewidth}
    \input{./figs/overview/framework.pdf_tex}
    \caption{Overview of general framework that combines logical
    and natural constraints in a single optimisation problem.} \label{fig:overview}
\end{figure}
This section introduces our general framework, shown in~\cref{fig:overview}
which we instantiate in the next section by building a tool for
predicting types in TypeScript.
\cref{fig:fullexample} illustrates our general framework through a running example of predicting types. 

\begin{figure*}
	\centering
	\def\svgwidth{\linewidth}
	\scalebox{.77}{\input{./figs/example/example.pdf_tex}}
	\caption[An overview of the three type inference procedures via a minimal example.]{Our input is a minimal JavaScript function
		with no type annotations on its parameters or result.
		%
		By default, TypeScript's compiler assigns its wildcard type \lstinline+any+ to
		parameters.
		%
		Our goal is to exploit both logical and natural constraints to suggest
		more specific types.
		%
		To begin, in Box (a), we propose fresh type annotations  \textcolor{mygreen}{\texttt{START}} and \textcolor{mygreen}{\texttt{END}} (uppercasing the identifier) for each parameter and \textcolor{mygreen}{\texttt{ADDNUM}} for the return type.
		%
		We insert these annotations into the function's definition.
		%
		Our \emph{logical constraints} on these types represent knowledge obtained
		by a symbolic analysis of the code in the function's body.
		%
		In our example, the use of a binary operation implies that the two parameter types are equal.
		%
		Box (c) shows a minimal set of logical constraints that state
		that \textcolor{RoyalBlue}{\texttt{addNum}}'s two operands have the same type.
		%
		In general, the logical constraints can be much more complex than our simple example.
		%
		If we only have logical constraints, we cannot tell
		whether \lstinline{string} or \lstinline{number} is a better solution,
		and so may fall back to the type \lstinline{any}.
		%
		The crux of our approach is to take into account \emph{natural constraints};
		that is, statistical properties learnt from a source code corpus that seek to
		capture human intention.
		%
		In particular, we use a machine learning model to capture naming conventions over types.
		%
		We represent the solution space for our logical or natural constraints
		or their combination
		as a $V \times T$ matrix $P$ of the form in Box (b):
		each row vector is a discrete probability distribution
		over our universe of $T=3$ concrete types
		(\lstinline{number}, \lstinline{string}, and \lstinline{any})
		for one of our $V=3$ identifiers.
		%
		Box (d) shows the natural constraints $\mathcal{M}$ induced by the identifier names
		for the parameters and the function name itself.
		%
		Intuitively, Box (d) shows that a programmer
		is more likely to name a variable \lstinline{start} or \lstinline{end}
		if she intends to use it as a \lstinline{number} than as a \lstinline{string}.
		%
		% The matrix uses probabilities to reflect our degree of certainty.
		%
		% Returning to the logical constraints,
		We can relax the boolean constraint
		to a numerical function on probabilities as shown in Box (c).
		When we numerically optimise the resulting expression,
		we obtain the matrix in Box (e);
		it predicts that both variables are strings with high probability.
		%
		Although the objective function is symmetric
		between \lstinline{string} and \lstinline{number},
		the solution in (e) is asymmetric because it depends on the initialisation
		of the optimiser.
		%
		Finally, Box (f) shows an optimisation objective that
		combines both sources of information:
		$E$ consists of the logical constraints
		and each probability vector $\mu_v$ (the row of $\mathcal{M}$ for $v$)
		is the natural constraint for variable $v$.
		%
		Box (f) also shows the solution matrix and Box (g) shows the induced type annotations,
    		now all predicted to be \lstinline{number}.}
	%	\begin{minipage}{\textwidth}
	%\end{minipage}%
\label{fig:fullexample}
\vspace{-13pt}
\end{figure*}
% Our goal is to enhance the type inference
% procedure for dynamic languages by incorporating into a single engine
% both information learned from a corpus of typed code
% as well as information derived directly from the code that is to be typed.
%
% We distinguish between two main kinds of constraints that we eventually
% combine in an optimisation problem.
% The next few subsections formalize this approach.

\subsection{An Outline of Probabilistic Type Inference}

We consider a dynamic language of untyped programs that is equipped with an existing deterministic type system,
that requires type annotations on identifiers.
%
Given a program $U$ plus a typing environment $\Gamma$ let $\Gamma \vdash U$ mean that the program $U$ is well-typed according to the (deterministic) type system, given types for identifiers provided by $\Gamma$.
%
Formally, a typing environment $\Gamma$ is a finite function
with domain $\{ x_v \mid v \in 1 \ldots V\}$, where $x_v$  is an identifier, and range $\{ l_\tau \mid \tau \in 1 \dots T \}$, where each $l_\tau$ is a literal type.
Given an untyped program $U$,
let \emph{probabilistic type inference} consist of these steps:
\begin{enumerate}
	\item We choose a finite universe consisting of $T$ distinct literal types $\{ l_\tau \mid \tau \in 1 \dots T \}$.
	\item We compute a set $\{ x_v \mid v \in 1 \ldots V\}$ of a number $V$ of distinct identifiers in $U$ that need to be assigned types.
	\item \label{step:constraints} We extract a set of constraints from $U$.
	\item \label{step:optimise} By optimising these constraints, we construct a matrix $P$ with $V$ rows and $T$ columns,
	      such that each row is a probability vector
	      (a discrete distribution over the $T$ literal types).
	\item For each identifier $x_v$, we set type $t_v$ to the literal type $l_\tau$ which we compute from the $v$th probability vector (the one for identifier $x_v$).  In this work, we pick the column $\tau$ that has the maximum probability in $x_v$'s probability vector.
	\item The outcome is the environment $\Gamma = \{ x_v : t_v \mid v \in 1 \ldots V\}$.
\end{enumerate}

We say that probabilistic type inference is \emph{successful} if $\Gamma \vdash U$, that is, the untyped program $U$ is well-typed according to the deterministic type system.
%
Since several steps may involve approximation, the prediction $\Gamma$ may only be partially correct.
%
Still, given a known $\hat{\Gamma}$ such that $\hat{\Gamma} \vdash U$ we can measure how well $\Gamma$ has predicted the identifiers and types of $\hat{\Gamma}$.
%
A key idea is that there are two sorts of constraints in step~(\ref{step:constraints}): logical constraints and natural
constraints.

A \emph{logical constraint} is a formula $E$ that describes
necessary conditions for $U$ to be well-typed.
In principle, $E$ can be any formula such that if $\Gamma \vdash U,$
then $\Gamma$ satisfies $E$.
Thus, the logical constraints
do not need to uniquely determine $\Gamma$.
% CS: I'm not sure if we want to use the phrase "type hints",
% because I feel like I have heard this phrase as a technical term elsewhere?
For this reason, a \emph{natural constraint}
encodes less-certain information about $\Gamma$,
for example, based on comments or names.
Just as we can conceptualise the logical
constraints as a function to the set of boolean values $\{0, 1\}$,
we can conceptualise the natural constraints as functions
that map $\Gamma$ to the set of probabilities $[0, 1]$, which can be interpreted
as a prediction of the probability that $\Gamma$ would
be successful. To combine these two constraints, we relax the boolean operations to continuous operators on $[0, 1]$.
Since we can conceptualise $E$ as a function
that maps $\Gamma$ to a boolean value $\{0, 1\}$,
we relax this function to map to $[0,1]$, using
a continuous interpretation of the semantics of $E$.
Similarly, we relax $\Gamma$ to a $V \times T$ matrix of probabilities.
Having done this,
we formalise type inference as a problem in
numerical optimisation, with the goal to find a relaxed type assignment
that satisfies as much as possible both sorts of constraints.
The result of this optimisation procedure is the
matrix $P$ of probabilities described in step~(\ref{step:optimise}).
% We explain the above formalization in more detail in the remainder of this section.

\subsection{Logical Constraints in Continuous Space}\label{ssec:logcon}

% The first source of information concerns classical and deterministic sources of
% information about types, which we abstract as logical formulas on type parameters.
% In programming languages terms, a type inference process
% introduces   and could be abstracted as
% generating logical constraints between them. 
%CS: commenting out the use of definition, because this isn't formal.
%\begin{defn}[\emph{Logical Constraints}]
% A \emph{logical constraint} is the kind of
% constraint that arises from classical
% type inference rules and consist of logical formulas about
% the type assignment.
%
% Classic program analysis aims to provide guarantees about properties of the
% code such as correctness or safety. For such tasks most commonly formal
% methods are being recruited to generate a set of constraints that has to be
% respected by the program.
% The logical constraints restrict the space of valid type annotations.
% However, especially for untyped programs, the resulting space might be large,
% CS: this is a meta-type error: a space is not a type
% the resulting space might turns out to be a general type, such
% as the top type, or a complicated sum type, which does not 
% add useful information to the system.
% and so is not on its own useful for type inference.

	% Therefore, instead of solving the problem
	% with classical approaches, like a SAT solver, we interpret the boolean
	% type expressions as numerical expressions in a continuous space.
	% %
	% This interpretation enables us to mix together the logical constraints with
	% information coming from statistical analysis in a constructive way and hence to
	% narrow down the predicted type.}

Logical constraints are extracted from our untyped input program $U$ using
standard program analysis techniques.  Here, we rely on a \emph{Constraint
	Generator} for this purpose. ~\autoref{ssec:logprodts} describes its
realisation.  The generator takes into account a set of rules that the type system
enforces and produces a boolean type constraint for them.

In this work, we consider the following logical constraints.
\begin{definition}[\emph{Grammar of Logical Constraints}]\label{def:log-gram}
	A \emph{logical constraint} is an expression $E$ of the following form:
	\begin{align*}
		E & ::= x_v \mathrel{is} l_\tau \\ \numberthis\label{eq:gram}
		  & \mid{} \mathrel{not} E      \\
		  & \mid E \mathrel{and} E      \\
		  & \mid E \mathrel{or} E.
	\end{align*}
	Let $\mathcal{E}$ be the set of all logical constraints.
\end{definition}

Recall that a typing environment $\Gamma$ is a finite function
with domain $\{ x_v \mid v \in 1 \ldots V\}$, and range $\{ l_\tau \mid \tau \in 1 \dots T \}$.
%
The standard \emph{logical satisfaction} relation $\Gamma \models E$, is defined by induction on the structure of $E$, as follows.
%
The typing environment $\Gamma$ plays the role of a model for the formula $E$.

          \begin{align*} 
              \Gamma \models x_v \mathrel{is} l_\tau & \Leftrightarrow \Gamma(x_v)=l_\tau                                  \\
              \Gamma \models{} \mathrel{not} E       & \Leftrightarrow{} \mbox{not $\Gamma \models E$}                    \\ \numberthis \label{eq:logsat}
              \Gamma \models E_1 \mathrel{and} E_2   & \Leftrightarrow
              \mbox{$\Gamma \models E_1$ and $\Gamma \models E_2$} \\
              \Gamma \models E_1 \mathrel{or} E_2
                                                     & \Leftrightarrow
        \mbox{$\Gamma \models E_1$ or $\Gamma \models E_2$.}
          \end{align*}

% CS: Commenting out notation that is already defined in the setup now.
\paragraph{Continuous Relaxation}
We explain how to specify a \emph{continuous relaxation} of the discrete logical semantics. Intuitively, the logical semantics defines a truth function that maps typing environments to $\{0, 1\}$; a continuous
relaxation extends the range of the truth function to $[0, 1].$
To see this, start with two auxiliary definitions:
\begin{itemize}
    \item We define $\Pi^{V \times T}$ to be the set
of all \emph{probability matrices} of size $V \times T$,
that is, matrices of the form $P = \begin{bmatrix} \bm{p}_1 & \ldots & \bm{p}_{V} \end{bmatrix}^\mathsf{T}$,
where each $\bm{p}_v = \begin{bmatrix} p_{v,1} & \ldots & p_{v,{T}} \end{bmatrix}^\mathsf{T}$
is a vector that defines a probability distribution over concrete types.
    \item We convert an environment $\Gamma$ into a $V \times T$ binary matrix $B(\Gamma)$ by setting $b_{v,\tau} = 1$ if $(x_v, l_\tau) \in \Gamma,$ and 0 otherwise.
    Each binary matrix is also a probability matrix: $B(\Gamma) \in \Pi^{V \times T}$.
\end{itemize}
Given a formula $E,$ we define a truth function $f_E: \{0, 1\}^{V \times T} \rightarrow \{0, 1\}$
that maps binary matrices to $\{0, 1\}$, namely, for all $\Gamma,$ we define $f_{E}(B(\Gamma)) = 1$ if and only if $\Gamma \models E$.
A \emph{relaxed semantics} is a continuous function
that always agrees with the logical semantics, that is,
a relaxed semantics is a function
$\tilde{f}_{E} : \Pi^{V \times T}  \rightarrow [0, 1]$
such that for all formulas $E$ and environments $\Gamma$,
$\tilde{f}_{E}(B(\Gamma)) = f_E(B(\Gamma))$.
Essentially, a relaxed semantics extends the domain and range
of $f_E$ to be continuous instead of discrete.

%for the 3 translations used the authors of that paper say using * may be better than the others. For the, why its better for optimization, this would require experiments, but one thing you can point to potentially if those work out, is that there is more gradient information in the product t-norm translation. 
% the product t-norm over the alternatives proposed by Godel and
% Lukasiewicz is that, when back-propagating from the loss to the clause weights, the gradients
% flow evenly between both Y1 and Y2. With Godel’s t-norm, there is no gradient information
% sent to Y1 when Y1 > Y2. Similarly, with Lukasiewicz’s t-norm, there is no gradient
% information sent to either Y1 or Y2 when Y1 + Y2 < 1.

% To define our relaxed semantics, we introduce a continuous semantics of $E$ based on generalisations of two-valued logical conjunctions to many-valued~\cite{hajek98}.
%
Our \emph{continuous semantics} (or relaxed semantics) $\qqpi{P}{E}$ is a function $\Pi^{V \times T} \times \mathcal{E} \rightarrow [0, 1]$,
defined by induction on the structure of $E$, as follows.
%an expression~$E$ as a probability~$\qqpi{P}{E} \in [0,1]$ as  follows.
%we are in log-space
%\ivp{Mention explicitly that this formulation maps scalar from [0,1] to [0,1], that is probability vectors do not require some extra form of scaling}
\begin{align*}
	\qqpi{P}{x_v \mathrel{is} l_\tau} & = p_{v,\tau}                        \\  \numberthis \label{eq:logical}
	\qqpi{P}{\mathrel{not} E}         & = 1-\qqpi{P}{E}                     \\
	\qqpi{P}{E_1 \mathrel{and} E_2}   & = \qqpi{P}{E_1} \cdot \qqpi{P}{E_2} \\
	\qqpi{P}{E_1 \mathrel{or} E_2}    & =
	\qqpi{P}{E_1} + \qqpi{P}{E_2} - \qqpi{P}{E_1}\cdot\qqpi{P}{E_2}.
\end{align*}
%The $\mathrel{is}$ relation describes that the probability that the type variable $x_v$ is the literal type $l_\tau$. 
(In the actual implementation, we use logits instead of probabilities
for numerical stability, see \cref{app:appendix-logit}.)
%
Our semantics is based on standard many-valued interpretations of propositional logic formulas as described for instance by \citet{hajek98}; however, our atomic propositions $x_v \mathrel{is} l_\tau$ and their interpretation via the matrix $P$ are original.
%
To interpret conjunction, we use what is known as the \emph{product $t$-norm}, where the conjunction of two constraints is interpreted as the numeric product of their interpretations:
$\qqpi{P}{E_1 \mathrel{and} E_2} = \qqpi{P}{E_1} \cdot \qqpi{P}{E_2}$.
%
We make this choice because the numeric product is smooth and fits with our optimisation-based approach.
%
The product $t$-norm has already been used for obtaining relaxed logical semantics in machine learning, for example by~\citet{rocktaschel15}.
%
Other choices are possible as we discuss in \autoref{ssec:softlogic}.

% Theorem 4.1.13 of the textbook by  and shows that in the product logic a formula $E$ is provable if and only if the continuous semantics of $E$ is $1$.

Our continuous semantics respects the duality between conjunction and disjunction:
\begin{lemma}[Duality]
For all $E_1$, $E_2$, and $P$:
\begin{enumerate}
    \item $\qqpi{P}{\mathrel{not}(E_1 \mathrel{and} E_2)} = \qqpi{P}{(\mathrel{not} E_1) \mathrel{or} (\mathrel{not} E_2)}$
    \item $\qqpi{P}{\mathrel{not}(E_1 \mathrel{or} E_2)} = \qqpi{P}{(\mathrel{not} E_1) \mathrel{and} (\mathrel{not} E_2)}$
\end{enumerate}
\end{lemma}
\iffalse
\begin{verbatim}
    not(E1 and E2) = (not E1) or (not E2)

[LHS]P = 1 - ([E1]P * [E2]P)
[RHS]P = (1-[E1]P) or (1-[E2]P)
 = (1-[E1]P) + (1-[E2]P) - ((1-[E1]P) * (1-[E2]P))
 = (1-[E1]P) + (1-[E2]P) - (1 -[E1]P -[E2]P + ([E1]P * [E2]P))
 = (1-[E1]P) + (1-[E2]P) -  1 + [E1]P + [E2]P - ([E1]P * [E2]P))
 = 1 - ([E1]P * [E2]P)
\end{verbatim}
\begin{verbatim}
    not(E1 or E2) = (not E1) and (not E2)

[LHS]P = 1 - ([E1]P + [E2]P - ([E1]P * [E2]P))
 = 1 - [E1]P - [E2]P + ([E1]P * [E2]P)
[RHS]P = (1-[E1]P) * (1-[E2]P)
 = 1 -[E1]P - [E2]P + ([E1]P * [E2]P)
\end{verbatim}
\fi % proof of the duality lemma

The following asserts essentially that the relaxed semantics is a continuous function that always agrees with the logical semantics.
\begin{theorem}[Relaxation]\label{thm:soft2hard}
For all E and $\Gamma$, we have that $\qqpi{B(\Gamma)}{E} = 1 \Leftrightarrow \Gamma \models E$.
\end{theorem}
The proof is by induction on the structure of $E$;
the details are in~\cref{app:proofs}.

Our general formulation of a relaxed semantics was in terms of the functions $f$ and $\tilde{f}$,
where we defined $f$ by $f_{E}(B(\Gamma)) = 1$ if and only if $\Gamma \models E$.
We sought a relaxed semantics $\tilde{f}$ which we can now define by: $\tilde{f}_E(P) = \qqpi{P}{E}$.
%
Our desired equation $\tilde{f}_{E}(B(\Gamma)) = f_E(B(\Gamma))$,
for all formulas $E$ and environments $\Gamma$,
follows as a corollary of \cref{thm:soft2hard}.

Recall that in our setting, we know $E$ but
do not know $\Gamma$.
To address that, we observe that because the continuous semantics $\tilde{f}_E(P) = \qqpi{P}{E}$ is a function of $P$, we can optimise numerically
the function $\tilde{f}_E(P)$ with respect to $P \in \Pi^{V \times T}$.
If the optimisation is successful in finding an optimal value $P^*$ such that
$P^* \approx B(\Gamma)$ for some $\Gamma$ and that $\tilde{f}_E(P^*) = \qqpi{P^*}{E} = 1$,
then the theorem tells us that we have a typing environment $\Gamma$ that models $E$.

% find a $\Gamma$ that satisfies the deterministic logical semantics $E$. One step further, by having the type assignments that satisfy $E$ we can obtain 
% Recall that in our setting, we know $E$ but
% do not know $\Gamma$. This is because it relaxes
% the deterministic logical semantics of $E$, and it is maximized
% by probability matrices $P$ which correspond to satisfying type environments. This is stated
% more formally in the following theorem.

% the continuous semantics,
% when considered as a function of $P$, can serve as a sensible
% objective for an optimisation problem to infer $P$.
% The reason is that it relaxes
% the deterministic logical semantics of $E$
% to $\qqpi{P}{E}$
% and it is maximised, that is equals to one,
% by probability matrices $P$ which correspond to satisfying type environments. 

% The following theorem formalises the idea:
% \begin{theorem}\label{thm:argmax}
% For all $\Gamma$ and all $E$,
% $\Gamma \models E$
% if and only if $B(\Gamma) \in \arg\max_{P \in \Pi^{V \times T}} \qqpi{P}{E}$.
% \end{theorem}
% For proofs see~\cref{app:proofs}.

\subsection{Natural Constraints via Machine Learning}\label{ssec:natcon}

A complementary source of information about types arises from statistical dependencies
in the source code of the program.  For example, names of variables provide
information about their types~\cite{xu16}, natural language in
method-level comments provide information about function types \cite{malik19},
and lexically nearby tokens provide information
about a variable's type~\cite{wei20,hellendoorn18}.
This information is indirect, and extremely difficult to formalise,
but we can still hope to exploit it by applying machine learning
to large corpora of source code.

Recently, the software engineering
community has adopted the term \emph{naturalness of source code} to refer to
the concept that programs have statistical regularities because
they are written by humans to be
understood by humans~\citep{hindle12}.
Following the idea that the naturalness in source code may be in part responsible
for the effectiveness of this information, we
refer generically to indirect, statistical
constraints about types as \emph{natural constraints}.
Because natural constraints are uncertain, they are naturally formalised
as probabilities.
A natural constraint is a mapping from a type variable to a vector
of probabilities
over possible types.
% Natural because they (the LSTM constraints) arise from a naturally occurring corpus 
% cf "On the naturalness of software".  But our method is modular and we could plug in
% other forms of language model, for instance.
\begin{definition}[\emph{Natural Constraints}]\label{eq:natural}
	For each identifier $x_v$ in a program $U$,
	a \emph{natural constraint} is a probability vector $\bm{\mu}_v = [\mu_{v1}, \ldots, \mu_{vT}]^\mathsf{T}$.
	We aggregate the probability vectors of the learning model in a matrix
	defined as $\mathcal{M} = \begin{bmatrix} \bm{\mu}_1 & \ldots & \bm{\mu}_{V} \end{bmatrix}^\mathsf{T}$.
	% Given such a matrix, we denote $M[v]$ for the probability vector $\bm{\mu}_v$.
\end{definition}

In principle, natural constraints can be defined based on any property of $U$,
including names and comments.
In this paper, we consider a simple but practically effective example of
natural constraint, namely, a deep network that predicts the type
of a variable from the characters in its name.
We consider each variable identifier $x_v$ to be a character sequence $(c_{v1} \ldots c_{vN})$,
where each $c_{vi}$ is a character.
(This instantiation of the natural constraint is defined
only on types for identifiers that occur in the source code,
such as a function identifier or a parameter identifier.)
This is a classification problem, where the input is $x_v$,
and the output classes are the set of $T$ concrete types.
Ideally, the classifier would learn that identifier names that are lexically similar
tend to have similar types, and specifically which subsequences of the character names,
like \texttt{\small{lst}}, are highly predictive of the type, and which subsequences are less predictive.
One simple way to do so is to use a recurrent neural network (RNN).

For our purposes, an RNN is simply a function $(\bm{h}_{i-1}, z_i) \mapsto \bm{h}_{i}$
that maps a state vector $\bm{h}_{i-1} \in \mathbb{R}^H$
and an arbitrary input $z_i$ to an updated state vector $\bm{h}_{i}  \in \mathbb{R}^H$.
(The dimension $H$ is one of the hyperparameters of the model, which can be tuned
to obtain the best performance.)
The RNN has continuous parameters that are learned to fit a given data set,
but we elide these parameters to lighten the notation, because they are trained in a standard way.
We use a particular variant of an RNN called a
long-short term memory network (LSTM)~\cite{hochreiter97},
which has proven to be particularly effective both for natural language
and for source code~\cite{sundermeyer2012,melis17,white2015,dam16}.
We write the LSTM as $\text{LSTM}(\bm{h}_{i-1}, z_i)$.

With this background, we can describe the specific natural constraint that we use.
Given the name $x_v = (c_{v1} \ldots c_{vN}),$ we input each character $c_{vi}$ to the LSTM,
obtaining a final state vector $\bm{h}_N,$ which is then passed as input to a small
neural network that outputs the natural constraint $\bm{\mu}_v$.
That is, we define
\begin{subequations}\label{eq:lstm}
	\begin{align}
		\bm{h}_i   & = \text{LSTM}(\bm{h}_{i-1}, c_{vi}) \qquad i \in 1, \ldots, N \\
		\bm{\mu}_v & = F(\bm{h}_N), \label{eq:lstmb}
	\end{align}
\end{subequations}
where $F: \mathbb{R}^H \rightarrow \mathbb{R}^T$ is a simple neural network.
In our instantiation of this natural constraint, we choose $F$ to be a feedforward neural network with
no additional hidden layers, as defined in \eqref{eq:feedforward}.
We provide more details regarding the particular structure of our neural network in \cref{ssec:natprodts}.

This network structure is, by now, a fairly standard architectural motif in deep learning.
More sophisticated networks could certainly be employed, but are left to future work.

\subsection{Combining Logical and Natural Constraints to Form an Optimisation
	Problem} \label{ssec:optimisation}
%\ivp{Explain why we need this part: NNs cannot handle hard constraints so this
%is our way to enforce them}

Logical constraints pose challenges to the probabilistic world of
machine learning.  Neural networks cannot handle hard constraints explicitly and 
thus it is not straightforward how to incorporate the logical rules that they must follow.
Our way around that problem is to relax the logical constraints to numerical
space and combine them with the natural constraints through a continuous
optimisation problem.

Intuitively, we design the optimisation problem to be over
probability matrices $P \in \Pi^{V \times T}$; we wish to find
$P$ that is as close as possible to the natural constraints $\mathcal{M}$
subject to the logical constraints being satisfied.
A simple way to quantify the distance is via the \emph{Euclidean norm} $|| \cdot ||_2$ of a vector,  which is a convex function and thus well suited with our optimisation approach.
%that is, the square root of the sum of the squares of its elements
Hence, we obtain the constrained optimisation problem
\begin{IEEEeqnarray}{c'c}\label{eq:opt_naive}
    \IEEEnonumber*
	\min_{P \in \mathbb{R}^{V \times T}} & \sum_v || \bm{p}_v - \bm{\mu}_v ||_2^2\\
	\text{s.t.} & p_{v\tau} \in [0, 1], \quad \forall v, \tau
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{c'c}
	& \sum_{\tau=1}^T p_{v\tau} = 1, \quad \forall v \\
	& \qqpi{P}{E} = 1.\nonumber
\end{IEEEeqnarray}
%
% \cas{This could alternately be formalised as a multi-objective problem. I do not know what is best.
% 	Maybe it is better to talk about maximizing [[ E ]], because our theorem talks about maximization.}
%

We use Mean Squared Error (MSE) here to quantify the performance of our fitting.
%We choose to use Mean Squared Error (MSE), also called the Brier score in statistics \cite{brier50, good52} instead of Cross Entropy (CE) which is is another common choice for probabilities.
We could have used the Cross Entropy (CE), another common loss function.  The
MSE is a proper scoring rule~\cite{gneiting07}, meaning that smaller values
correspond to better matching of our optimisation variables with the logical
constraints.  We do not claim any particular advantage of MSE versus CE.

Instead of solving optimisation problem \eqref{eq:opt_naive}, we proceed to make some remarks that exploit its structure.
First, we reparameterise the problem to remove the probability constraints, by using the softmax function
\begin{equation}\label{eq:softmax}
	\sigma(\bm{x}) = \left[\frac{\exp\{x_1\}}{\sum_i \exp\{x_i\}}, \frac{\exp\{x_2\}}{\sum_i \exp\{x_i\}}, \cdots \right]^\mathsf{T},
\end{equation}
which maps real-valued vectors to probability vectors.
Our transformed problem takes the form
\begin{equation}
	\begin{aligned}\label{eq:opt_no_prob}
		\underset{Y \in \mathbb{R}^{V \times T}}{\mathrm{min}} & \quad
		\sum_v || \sigma(\bm{y}_v) - \bm{\mu}_v ||_2^2                                                                         \\
		\text{s.t. } & \quad
		\qqpi{[\sigma(\bm{y}_1), \ldots, \sigma(\bm{y}_{V})]^\mathsf{T}}{E} -1 = 0.
	\end{aligned}
\end{equation}
It is easy to see that for $Y^*$ that minimises \eqref{eq:opt_no_prob}, then
$P^* = [\sigma(\bm{y}_1), \ldots, \allowbreak \sigma(\bm{y}_{V})]^\mathsf{T}$
minimises \eqref{eq:opt_naive}.
% 
We remove the last constraint by introducing a multiplier $\lambda \in \mathbb{R}$, 
yielding the final form of our optimisation problem
\begin{equation}\label{eq:objective}
	\min_{Y, \lambda}
	\sum_v || \sigma(\bm{y}_v)^\mathsf{T} - \bm{\mu}_v ||_2^2
	- \lambda \big(\qqpi{[\sigma(\bm{y}_1), \ldots, \sigma(\bm{y}_{V})]^\mathsf{T}}{E} - 1\big).
\end{equation}
This corresponds to the Lagrange multiplier method~\citep{bertsekas82}.
According to the first-order necessary conditions, at a saddle point of the objective function of~\eqref{eq:objective} the following conditions should be satisfied
\begin{subequations}
\begin{align}
    \nabla_Y L(Y, \lambda) & = 0\\
    \nabla_\lambda L(Y, \lambda) & = 0,\label{eq:langrange_constraint}
\end{align}
\end{subequations}
where $L(Y, \lambda)$ equals the objective of~\eqref{eq:objective}.
Equation~\eqref{eq:langrange_constraint} guarantees that at our optimisation's problem solution, the equality constraint in~\eqref{eq:opt_no_prob} is satisfied.
In general, the necessary conditions are concerned with a saddle point.
In our experience, we have not faced any issue converging to optimal solutions when starting with large initial values for $\lambda$.
Nevertheless, a more systematic study is required for removing such possibilities.

Finally, we note that by adding more terms to the combined objective function, we can 
extend the sources of information we are getting as inputs to other channels, such as dynamic analysis.

% For this part the trick is that whether the logical constraints are satisfied at the optimum
%  depends on lambda. Does that make sense?
% If lambda = 0 the logical constraints are not guaranteed to be satisfied,
% and I expect that if we look at the predictions produced in our experiments, we will find sometimes that the constraints are not satisfied. 

% (There are two general strategies in the above about how to approach theoretical claims:
% understand the limiting case because that is often simpler,
% and try out a simpler implementation to see if the proposed theorem is true.)

% Instead what I claim is that there exists a value lambda0 such that,
% as long as you pick lambda > lambda0, then the constraints are satisfied at optimum.

% This depends on two ideas:
% One, I claim that if you consider the logical constraints as a function
% of the continuous type assignments,
% we show under some conditions this function is bounded above by 1,
% and that if the function is 1, then the constraints are satisfied.
% (I can try to do this more formally once I have our notation from the paper.)

% Then we argue that the likelihood term has a gap between the best non satisfying assignment
% and the best satisfying one.
% If lambda is big enough, the gap in the logical constraints is bigger
% than the gap in the natural constraints, so the overall optimum will satisfy the logical constraints
\section{\projectname: Predicting Types for TypeScript}
\label{sec:prodts}
To evaluate our approach in a real-world scenario, we
implement an end-to-end application, called \projectname, which aims
to suggest missing types for TypeScript files. The goal of
\projectname{}'s implementation 
is to serve as a proof of concept for our general framework. Thus, we acknowledge that our mechanisms to generate logical and natural constraints are both pragmatic under-approximations, and could in further work be replaced by more sophisticated mechanisms.
For instance, as every learning model outputs a probability vector over types, we can extend our method to include natural constraints generated by LambdaNet, JSNice or indeed any other deep learning approach that offers probability vectors as output types. 
For logical constraints, while
the grammar of logical constraints defined
in equation~\eqref{eq:gram} allows us naturally to express inference rules, the type constraints that \projectname handles in practice are confined to  
those inference rules we translate into logical expressions.
Unfortunately, the TypeScript compiler's type inference does not output logical constraints, so we 
have taken the pragmatic approach of only 
harvesting a subset of them. 
Even under the constraints of these two implementation choices for extracting logical and natural constraints, we show that \projectname outperforms JSNice and DeepTyper; its results are also somewhat better than those of LambdaNet.
\begin{figure*}[t]
    \begin{minipage}[c]{\textwidth}
\begin{lstlisting}[language=JavaScript]
   function toByteArray<B64, TOBYTEARRAY>(b64: B64): TOBYTEARRAY {
        ...
      var len = b64.length; // B64 !$\mathrel{is}$! String !$\mathrel{or}$! Array<any>
        ...
      tmp = (revLookup[b64.charCodeAt(i)] << 18) // B64 !$\mathrel{is}$! String
  }
\end{lstlisting}
    \vspace{-7mm}
    \end{minipage}
    \caption{A snippet from base64-js lib showing the extraction of two logical constraints (lines 3,5).}\label{fig:jscode-base64}
\end{figure*}

\subsection{Background: TypeScript's Type System}~\label{ssec:intro-typescript}

TypeScript~\citep{typescript} is a typed superset of
JavaScript designed for developing large-scale, stable applications.
TypeScript's compiler (\lstinline+tsc+) typechecks TypeScript programs then emits plain JavaScript,
to leverage the fact that JavaScript is the only cross-platform
language that runs in any browser, any host, and any OS.
Structural type systems consider record types (classes), whose fields or members have the same names and types, to be equal.
TypeScript supports a
structural type system because it permits TypeScript to handle many JavaScript idioms that depend on dynamic typing.
One of the main goals of TypeScript's designers is to support idiomatic
JavaScript to
provide a smooth transition from JavaScript to TypeScript.
%
Therefore, TypeScript's type system is deliberately
unsound~\citep{understandtypescript}.  It is an optional type system, whose
annotations can be omitted and have no effect on runtime. As, TypeScript erases 
them when transpiling to JavaScript~\citep{understandtypescript}.
We note, that TypeScript's type system defaults to assigning its \texttt{\small{any}} type to unannotated function or method parameters.  
% Function returns are an exception;
% here, TypeScript does seek to infer a more specific type.

% TypeScript applications and libraries commonly take advantage of JavaScript's flourishing ecosystem
% and use untyped JavaScript libraries.
% To support static type checking of such applications,
% the types of such JavaScript libraries' APIs are expressed
% as separate TypeScript~\emph{declaration files} (\lstinline{.d.ts}).
% The TypeScript community actively supports this process by manually writing and maintaining
% declaration files, available in the 
% DefinitelyTyped~\citep{definitelytyped} repository.
% Although this manual approach has proven
% useful, it raises the challenge of keeping declaration files
% in sync with the library implementations.

% Ideally, we would like to automatically infer the typed APIs of such libraries.
% For generating definition files for existing JavaScript libraries,
% the DefinitelyTyped
% community officially recommends \textit{dts-gen}~\citep{dtsgen}.
% This tool uses runtime information to produce a \lstinline{.d.ts} file that
% hepls to define the shape of the input API but does not provide type information for
% function arguments and returns. Because \textit{dts-gen} only collects
% dynamic information it eventually emits many \texttt{\small{any}} types that the developer must refine manually.
% It is only meant to be used as a starting
% point for writing a high-quality declaration file.
\subsection{Logical Constraints for TypeScript}
\label{ssec:logprodts}

%
\begin{table*}[t]
	\centering
	\caption{Different kinds of type hints from which \projectname generates \textit{Logical} constraints.}
	\label{tab:constraints}
	\begin{tabularx}{\textwidth}{lX}
		\toprule
		Kind & Description                                                                                  \\
		\midrule
		Assign         & Type $X$ is not assignable to type $Y$.                                                              \\
		SupType      & Property $X$ does not exist in type $Y$.                                                     \\
		Return      &  The return type of $X$ is $Y$.\\
		Operator         & Operator $\oplus$ cannot be applied
		to types $X$ and $Y$.                                                                                        \\
		Index         & Type $X$ cannot index type $Y$.                                                              \\
		
		ArithLHS      & The left-hand side of an arithmetic operation must be
		an \texttt{\small{enum}} type or have type \texttt{\small{any}} or \texttt{\small{number}}.    \\
		ArithRHS      & The right-hand side of an arithmetic operation must be
		an \texttt{\small{enum}} type or have type \texttt{\small{any}} or \texttt{\small{number}}. \\
		\bottomrule
	\end{tabularx}
	\vspace{-3.5mm}
\end{table*}


To generate the logical constraints of \cref{ssec:logcon}, we exploit the information from \lstinline+tsc+, the TypeScript compiler~\cite{typescript}. 
As \lstinline+tsc+ does not, generate a logical formulas 
for its type inference procedure we devise the following technique that allows us to generate some logical constraints based on \lstinline+tsc+'s information. To do so, we harvest type constraints from type hints that \lstinline+tsc+ may generate
for untyped identifiers. Because \lstinline+tsc+ always infers \texttt{\small{any}} for parameters we trigger
the compiler by assigning a fresh generic type variable to each parameter declaration node, and then invoke \lstinline+tsc+. 
Inferring return types is an easier task for the compiler and is the reason why the \textit{Logical} phase of our method works better for return types than parameters, as shown in ~\cref{tab:typeacc1}. 
We identify common type hints that the \lstinline+tsc+ compiler produces, and turn them into type constraints, \cref{tab:constraints}. The first row 
refers to identifying properties or methods that a type should implement
and we are using them to generate an $\mathrel{or}$ type constraint as follows. Additionally, to the file that we 
predict types for we take as an input the \lstinline{lib.d.ts} \footnote{\url{https://github.com/Microsoft/TypeScript/blob/master/lib/lib.d.ts}} file which includes interfaces for the default library types that the language implements. In that way when we find that an interface has a signature for a property that our injected type variable implements, we can generate a constraint for that particular type variable. If more the one interfaces have this propety, we generate an $\mathrel{or}$ constraint.
For a concrete example of this procedure, 
see~\cref{fig:jscode-base64}.
Our logical constraints include propositional logic, and therefore seem able to express a wide range of interesting type constraints~\citep{odersky99,pottier05}.
%
This technique seems a useful device that could be employed in other situations, and serves our purpose.
%

\paragraph{Implementation Details} 
In our framework both solving the relaxed logical constraints alone, and combining them with the natural constraints correspond to an optimisation 
problem as described in~\eqref{eq:logical} and
~\eqref{eq:objective} respectively. To find the minimum of the generated function we use 
\textsc{RMSprop}~\cite{tieleman2014};
an alternative to stochastic gradient descent~\cite{robbins51}, with an adaptive learning rate.Both the code for the deep
learning and the combined optimisation part is written in
PyTorch~\cite{paszke2017}.
\subsection{Natural Constraints for TypeScript}\label{ssec:natprodts}

To learn naming conventions over types we use a Char-Level LSTM which predicts for any identifier a probability vector over all the available types. Our model is trained on
\textit{(id, type)} pairs with the goal to learn naming conventions
for identifiers, treated as sequences of characters.
The main intuition behind this choice is that
developers commonly use multiple abbreviations for the same word and
this family of abbreviations shares a type.
A Char-Level model is well-suited to predict the type for any identifier in
an abbreviation families.

\begin{figure*}[!t]
    \centering
    \def\svgwidth{\linewidth}
    \input{./figs/char-level/char-level.pdf_tex}
  \caption{Pipeline of learning naming conventions with 
  a Char-Level \textit{LSTM}, represented by a probability vector for each identifier.
  }\label{fig:Char-Level}
\end{figure*}

\paragraph{Dataset} Following the work of 
~\citet{wei20} and~\citet{hellendoorn18},
to train our model we use as dataset the 300 
most starred Typescript projects from Github, 
containing between 500 to 10,000 lines of code.
Our dataset was randomly split by project into $80\%$ training data, $10\%$ validation data and $10\%$ test data. \cref{fig:Char-Level} shows a summary of the pipeline used to train our model, for specific implementation details of the LSTM refer to \cref{app:neural}.  
%
\paragraph{Prediction Space}
We define our type vocabulary to consist of top-100 most common default library types in our training set. As~\citet{wei20} report, this prediction space covers $98\%$ of the non-any annotations for the training set. We choose to consider only built-in types 
to ensure that we do not introduce types that are not available to the compiler. Handling a larger set of types is straightforward, but we decided instead to work with the same set of library types used by \citet{hellendoorn18} and \citet{wei20}, to be consistent in our comparisons.
Conforming to the practice of prior work in this space \cite{wei20,hellendoorn18,xu16,raychev15}, 
we consider all different polymorphic type arguments to be \texttt{\small{any}}; for example a \texttt{\small{Promise<boolean>}} type corresponds to \texttt{\small{Promise<any>}}.
%
Accordingly higher-order functions correspond to the type \texttt{\small{Function}}.
%
\paragraph{Implementation Details}
Regarding the implementation details of the LSTM network, for the $F$ in \eqref{eq:lstmb},
we use a feedforward neural network
\begin{equation}
	F(\bm{h}) = \log\left( \sigma\left(\bm{h}A^T + b \right) \right),\label{eq:feedforward}
\end{equation}
where the $\log$ function is applied componentwise,
and $A$ and $b$ are learnable weights and bias.
The softmax function \eqref{eq:softmax} corresponds to the last layer of our neural network
and essentially maps the values of the previous layer to $[0, 1]$,
while the sum of all values is $1$ as expected for a probability vector as already explained.
We work in log space to help numerical stability since computing \eqref{eq:softmax} directly can be problematic.
As a result, $F$ outputs values in $[-\infty, 0]$.

We train the model by supplying sets of variable identifiers together with their known types,
and minimizing a loss function.
Our loss function is the negative log likelihood function---conveniently combined with our log output---defined as
\begin{equation}
	L(\bm{y}) = -\sum_i log(\bm{y}_i).
\end{equation}
Essentially, we select, during training, the element that corresponds
to the correct label from the output $F$
and sum all the values of the correct labels for the entire training set.


% \subsection{Realisation of \projectname{}}\label{ssec:combprodts}

% We set the maximum number of iterations to 2,000, which suffices in practice for the loss to stabilise.


% We use \textsc{Adam}~\cite{kingma2014}, an extension of stochastic gradient descent~\cite{robbins51},
% as our optimisation algorithm for the natural constraints.
% %
% The main difference between \textsc{Adam} and classical stochastic gradient descent
% is the use of adaptive instead of fixed learning rates.
% %
% Although there exist other algorithms with adaptive learning rates
% like \textsc{AdaGrad}~\cite{duchi2011} and \textsc{RMSprop}~\cite{tieleman2014},
% \textsc{Adam} tends to have better convergence~\cite{ruder2016}.

% Adam~\cite{ruder2016} is being used to change the step of the optimizer on each iteration. 
\section{Evaluation of \projectname{}}\label{sec:eval}

This section opens with \autoref{sec:acc}, which defines the prediction and query spaces, explains the experimental setup and establishes the performance measure we use throughout the section.
\projectname is built to combine and exploit both logical and natural constraints, so \autoref{ssec:ablation} quantifies their separate contributions and demonstrates their synergy.
It then compares and analyses the performance of \projectname with that of LambdaNet and DeepTyper.
It closes by comparing \projectname with JSNice, the pioneering work in probabilistic type inference.

% \paragraph{Experimental Setup}

% All experiments are conducted on an NVIDIA Titan Xp with 12GB VRam,
% in combination with a 2-core Intel Core i5 CPU with 8GB of RAM.
% Our resulting model requires about 400MB of RAM to be loaded into memory and can be run on both a GPU and CPU.
% It computes type annotations on average for 58 files in about 60 seconds
% for solving logical constraints and natural constraints, and in about 65 seconds for the combined optimisation.

\subsection{Type Prediction Accuracy}\label{sec:acc}

For a statically typed language, let a declaration slot be a point in a program text where the grammar permits annotating an identifier with its type, including parameters within a function declaration; there is one such point for each identifier in the program.  Predicting types is a multi-class prediction task: at each annotation slot, we ask the predictor to propose a type from our type vocabulary, $\mathcal{T} = \{ l_\tau \mid \tau \in 1 \dots T \}$. We note that $\mathcal{T}$ does not include the gradual \texttt{\small{any}} type or Out-Of-Vocabulary \textit{OOV} token.  Concretely,
\autoref{ssec:natprodts} defines $\mathcal{T}$.

\autoref{fig:type:prediction:query} shows the query space for types in an optional type setting.
TypeScript itself defines built-in types.  Library types are those types defined by the libraries a project imports and project types, sometimes called user types in the literature, are those types a project defines itself. 
In general, developer annotations are those slots that a developer is likely to annotate; in training data, we under-approximate these slots by the slots that a developer did annotate. 
The compiler inferable slots are those slots for which an optional compiler can infer a type given the developer annotations.  
Developers annotate some slots to document and clarify the code, to aid navigation and completion, and so that the compiler can infer types for other slots.  
Developer annotated slots are special for two reasons:  they provide a natural source of labelled training data and, since developers went to the effort of annotating them, relieving developers of the burden of doing so is clearly useful.

\begin{figure*}[t]
    \centering
    \def\svgwidth{0.8\linewidth}
    \input{./figs/annotations/annotations.pdf_tex}
    \caption{The query space for probabilistic type suggestion for an optionally typed language.}
    \label{fig:type:prediction:query}
\end{figure*}

Let $\mathit{TP_i}$ be the number of times that a probabilistic type predictor \emph{correctly} labelled a slot with the $i^\text{th}$ type in $\mathcal{T}$;  let $\mathit{FP_i}$ be the number of times that the type predictor \emph{incorrectly} labelled a slot with the $i^\text{th}$ type.  Our ground truth for determining whether a prediction is correct is the set of developer annotated slots; in our test set, we call this set the \texttt{gold} file. 
This is a working assumption in the sense that some files may contain errors~\cite{williams17}.

We report performance using accuracy~\cite{manning}, defined as 

\begin{align}\label{eq:acc}
    \sum_i^T \frac{\mathit{TP_i}}{\mathit{TP_i} + \mathit{FP_i}},
\end{align}
where $T=|\mathcal{T}|$. In multi-class prediction, accuracy  coincides with micro-averaged precision. To see that, consider a multi-class confusion matrix.  The correct predictions are along its diagonal; the incorrect ones fall into all the other cells.  A correct prediction is both a TP positive, because the predictor choose the correct class, and a true negative, because the predictor did not incorrectly choose any other class.  An incorrect prediction is both a FP and a FN, by the same reasoning.  Under these conditions, accuracy reduces to \eqref{eq:acc}.
So, following related work~\cite{wei20}, we use accuracy to refer to this metric in the evaluation that follows.  To be consistent with previous work~\citep{wei20,hellendoorn18}, we perform the evaluations that follow on \textit{developer annotation slots}, while as we described
~\cref{ssec:natprodts} we use the same training data.


\subsection{Ablation Analysis:  Leveraging Both Logical and Natural Constraints}\label{ssec:ablation}
\begin{table*}[t]
	\centering
	\caption{Ablation analysis of \projectname, the cells report accuracy; FN refers to return types of functions and PARAM
	represents parameters.}
\label{tab:typeacc1}
	\begin{tabular}{ccccccc}
		\toprule
		Tool  & $\textit{FN}$ & 
		$\textit{PARAM}$ & $\textit{TOTAL}$ \\
		
		\midrule
		\textit{Logical}      & 0.56                                   & 0.23                                 & 0.29                                  \\
		\textit{Natural}      & 0.27                                    & 0.62                                 & 0.52                                   \\
		\projectname  & 0.66         & 0.75         & 0.74\\
		\bottomrule
	\end{tabular}
\end{table*}
\projectname has two phases --- logical and natural --- and combines them.  To evaluate the effect of each stage, \cref{tab:typeacc1} reports the accuracy of each stage.
\cref{tab:typeacc1}'s columns define disjoint sets of declaration slots.
Regarding the \textit{Logical} approach, the results are significantly better for function return types
than parameter types.
This happens because the \projectname harvests a richer set of constraints for return types.
For parameter types, the compiler always 
infers its gradual \texttt{\small{any}}, essentially making no inference at all. Therefore, it produces no useful logical constraints for parameters.
To mitigate this issue, we define some simple heuristics (\cref{ssec:logprodts}) that extract constraints for the \textit{Logical} stage to consider. This approach produces an average total of approximately 20 constraints per file. 

For the \textit{Natural} phase, the results swap, the prediction accuracy for the parameters' is double than the one for the return types. Our assumption is that
this is a result of largely using the same parameters ids over different projects, for example \lstinline{path}, than using the same function ids. Nevertheless, the results from our Char-Level model indicate that just the naming of a variable carries a
lot of information about its actual type;   
Overall, \cref{tab:typeacc1} show that the \textit{Logical} and \textit{Natural} phases complements each other and thus their combination in \projectname greatly improves our type inference capabilities.

\subsection{Comparison with DeepTyper and  LambdaNet}\label{ssec:typesubproblem}

\begin{table*}[t]
	\centering
	\caption{Accuracy for DeepTyper, LambdaNet and OptTyper; on $600$ annotations slots.}
		\label{tab:typeacc2}
	\begin{tabular}{ccccccc}
		\toprule
		Tool   &                              $Acc$ \\
		\midrule
		DeepTyper  & 0.63 \\
		LambdaNet  & 0.71 \\
		\projectname & 0.74\\
		\bottomrule
	\end{tabular}
\end{table*}

There are two main differences between DeepTyper 
and OptTyper that we need to address. Firstly, DeepTyper considers a much larger prediction space of $T=1100$ types, including many project types. Thus, to measure the accuracy, we restrict the prediction space to 100 library types (a subset of DeepTyper's vocabulary, exactly those \citet{wei20} chose when comparing DeepTyper to LambdaNet.
Secondly, DeepTyper predicts a type, sometimes different, for each occurrence of an identifier, while we predict types only for declaration slots. To address this, we compare \projectname{} with a DeepTyper variant proposed by~\citet{wei20}.
This variant makes a single prediction for each identifier, by averaging over the RRN internal states for a particular identifier before the actual prediction.
The DeepTyper results we report are for this variant, retrained over the vocabulary of 100 library types specified above, using top-1 accuracy.

\cref{tab:typeacc2} summarises the results of our comparisons. We conjecture that \projectname outperforms DeepTyper mainly because \projectname's logical constraints define
a wider, lexically independent, prediction context than DeepTyper.
Perhaps taking into account only information in the vicinity as DeepTyper does can be problematic;
for instance, function definitions may be placed relatively far away from their calls and hence the context, that DeepTyper learns, is not very informative.
\begin{figure}[!t]
    \centering
    \begin{minipage}[t]{.38\textwidth}
        \raggedright
\begin{lstlisting}[language=JavaScript,label={lst:gold}, numbers=left]
  function f1(
    x: boolean,
    z: Window,
    y: Event
  ): number {
      x = true;
      z = window;
      y = Event.prototype;
      return 1;
  }
\end{lstlisting}
    \vspace{-7mm}
    \subcaption{Gold TypeScript file.}
    \end{minipage}
    \begin{minipage}[t]{.57\textwidth}
        \raggedleft
\begin{lstlisting}[language=Fake,label={lst:lncode}] 
function !$\mathscr{P}1\{\text{f}1\}($!
  !$\mathscr{P}2\{\text{x}\}\textcolor{mygreen}{: \mathscr{L}}$\textcolor{mygreen}{[ty]\{Boolean\}}!,
  !$\mathscr{P}3\{\text{z}\}\textcolor{Maroon}{: (\mathscr{L}}$\textcolor{Maroon}{[ty]\{String\} \ne \ }$\textcolor{Maroon}{\mathscr{L}}$\textcolor{Maroon}{[ty]\{Window\})}!,
  !$\mathscr{P}4\{\text{y}\}\textcolor{Maroon}{: (\mathscr{L}}$\textcolor{Maroon}{[ty]\{Number\} \ne \ }$\textcolor{Maroon}{\mathscr{L}}$\textcolor{Maroon}{[ty]\{Event\})}!
): (!$\mathscr{P}5$$\textcolor{mygreen}{: (\mathscr{L}}$\textcolor{mygreen}{[ty]\{Number\}}!) {
    !$\mathscr{P}2\{\text{x}\} \leftarrow \mathscr{L}\{\text{Boolean}\}$!;
    !$\mathscr{P}3\{\text{z}\} \leftarrow \mathscr{L}\{\text{window}\}$!;
    !$\mathscr{P}4\{\text{y}\} \leftarrow \mathscr{L}\{\text{Event}\}\text{.prototype}$!;
    return !$\mathscr{P}5 = \mathscr{L}\{\text{Number}\}$!
}
\end{lstlisting}
    \vspace{-7mm}
    \subcaption{LambdaNet output.}
    \end{minipage}
    \caption{Minimal example showing 2 cases where LambdaNet gives incorrect predictions.}\label{fig:LambdaNet}
\end{figure}

The comparison with LambdaNet is straightforward because they provide a pretrained model trained on the same dataset and for the same set of types as ours. 
\cref{tab:typeacc2} shows that our accuracy is on par with LambdaNet's, and indeed somewhat better.
The closely comparable performances of the two approaches is strong evidence that logical constraints are critical to accurate type prediction. 

As we have discussed (See \autoref{sec:related} for details), 
LambdaNet's predictions may not type check.  We have found examples where this occurs. \cref{fig:LambdaNet} shows two examples.  
The parameters on lines 3 and 4 actually have type Window and Event, as you can see in \cref{lst:gold}, which contains the developer-annotated ground truth.
\cref{lst:lncode}, the figure on the right, shows that LambdaNet mispredicts their types as String and Number.
%
We conjecture that the misprediction is because of data sparsity.
%
LambdaNet correctly predicts the type of the first parameter because uses of \texttt{boolean} are relatively common in the training data, while uses of \texttt{Window} and \texttt{Event} are not, so the assignments on lines 7 and 8 provide too little signal for LambdaNet to pick up.
\projectname, in contrast, correctly predicts all three parameter types.
\projectname succeeds here because the assignments on lines 7 and 8 generate hard logical constraints that \projectname incorporates, \emph{at test time}, into its optimisation search for a satisfying type environment.
These examples may explain the difference between LambdaNet's and OptTyper's prediction accuracy. 
This difference in performance between the two approaches will crop up whenever the training data lacks sufficient number of examples of a particular logical relation.

% Create constraints for {y}.
% transform.ts:374
% (x): Type 'true' is not assignable to type 'x'.
% transform.ts:112
% (z): Type 'Window' is not assignable to type 'z'.
% transform.ts:112
% (y): Type 'Event' is not assignable to type 'y'.
\subsection{Comparison with JSNice}
%
Only portions of the JSNice~\cite{raychev15} system have been made open source. 
The portion of the implementation that the authors have made public is not sufficient to retrain the JSNice models. 
Instead, we follow the approach of~\citet{hellendoorn18} and~\citet{wei20} and manually compare JSNice and \projectname over a smaller dataset. 
As JSNice targets JavaScript, it cannot predict types for classes or interfaces, so we report accuracy on top-level functions return types and parameters randomly sampled from our test set. The prediction
space for this comparison is restricted to JavaScript primitive types.

\begin{table*}[t]
	\centering
	\caption{Accuracy for JSNice and OptTyper; on 107 annotations slots.}
		\label{tab:typeacc3}
	\begin{tabular}{ccccccc}
		\toprule
		Tool   & $Acc$ \\
		\midrule
		JSNice     & 0.45\\
		\projectname & 0.71\\
		\bottomrule
	\end{tabular}
\end{table*}

As \cref{tab:typeacc3} shows, \projectname outperforms JSNice. We conjecture that this is because JSNice exploits the relation paths between types up to a shallow depth, and thus it may not
capture some typing relevant element dependencies. 
In contrast, our logical constraints can leverage information of a more expansive context.
Additionally, \projectname's grouping together of names that share a type despite minor variations in their names could be proven useful for learning techniques.

% JSNice~\cite{raychev15} is a tool based on probabilistic graphical models which analyses relationships
% between program elements to infer types for JavaScript files.

% \cas{I agree it would be fairly simple to extend the method to handle DeepTyper or NL2Type constraints; we could simply add more terms to combined objective function, one for each kind of LSTM that we want to add. I'd view the character-level LSTM that we use as a representative kind of natural constraint, but not necessarily the best, and certainly not the only one. We should mention that in the paper..
% 	Finally, it seems like there is quite some opportunity for a hybrid here; in fact, a fairly simple extension to e.g. DeepTyper (or NL2Type) could allow your "natural" component to factor in a much broader context and likely work much better correspondingly. Happy to chat about that sometime
% 	richer type
% 	annotation holds the promise of a more precise, modular and extensible analysis, and
% 	as the need of building programs that conform the specifications emerges we
% 	should therefore search for novel and universally applicable solutions
% }%

%42 libs, 106 parameters, 78 funRet, 184 total 
% To compare \projectname against DeepTyper we run the tool for every library in  our dataset.
% As a first step, we extract a dictionary with the prediction for each of the identifiers presented in the corresponding declaration file for that
% library and lastly we filled the type holes in the structure declaration file with
% the predictions that the DeepTyper gives.
% We also note that because the DeepTyper
% type-annotates every identifier, without performing any static analysis, eventually
% produces code that does not compile. To alleviate this problem on comparing our results,
% we discard the \texttt{\small{any}} type as prediction, if we have a second best candidate. 
% The naive Char-Level, which learns only the correlation between an identifier and a type 
% is a comparable with
% DeepTyper which take into account more context than just the identifier. DeepTyper
% performance drops for the return types compared both with the Char-Level but also 
% with DeepTyper's perfomance for parameters, we believe that this happens for three
% reasons:


\section{Related Work}~\label{sec:related}

\projectname is a new form of probabilistic type inference that optimises over
both logical and natural constraints.  Related work spans classical, deterministic
type inference, soft logic for the relaxation of the constraints, and earlier machine learning approaches.

\subsection{Classical Type Inference}

% \adg{There are purely statically typed languages, with powerful inference, so that annotations are infrequent.
% 	Any work to date on ML for statically typed languages?  Not AFAIK}
% \etb{There is work on ML for statically typed languages for the autocompletion
% 	task, but not for type inference.}

Rich type inference mitigates the cost
of explicitly annotating types. This feature is an
inherent trait of strongly, statically-typed, functional languages (like Haskell or ML).

% In this direction, some procedural languages attempt to
% include type inference as a feature.
% For instance, in C\texttt{++}
% programmers can use the auto keyword to avoid writing the type in the
% definition of a variable with an explicit initialization, while in
% C{\#} (starting with version 3) the var keyword can be used as a
% convenient syntactic sugar for shorter local variable declarations.
% Nevertheless, C{\#} is still a statically typed language. These
% enhancements are implemented via compiler tricks and thus are considered as a
% small step towards a world of static typing where possible, and dynamic
% typing when needed.

Dynamic languages have also started to pay more attention to typings. Several
JavaScript extensions, like Closure Compiler~\citep{closure}, Flow~\cite{flow} and
TypeScript (See \cref{ssec:intro-typescript}) are all focusing on enabling
sorts of static type checking for JavaScript.
%
% In JavaScript, these annotations are
% provided by specially formatted comments known as JSDoc~\citep{jsdoc}.
%
However, these
extensions often fail to scale to realistic programs that make use of dynamic
evaluation and complex libraries, for example, jQuery, which cannot be analysed
precisely~\cite{jensen09}.
%
There are similar extensions for other popular scripting languages,
like~\citep{mypy}, an optional static type checker for Python,
or RuboCop~\citep{rubycop}, which serves as a static analyzer for Ruby by enforcing many of the guidelines
outlined in the community Ruby Style Guide~\citep{rubystyle}.
%and performing various check types known as cops.

The quest for more modular and extensible static analysis techniques has
resulted in the development of richer type systems.
Refinement types, that is, subsets of types that satisfy a logical predicate (like Boolean expression),
constrain the set of values described by the type and hence allow the use of
modern logic solvers (such as SAT and SMT engines) to extend the
scope of invariants that can be statically verified.
An implementation of this concept comes with Logically Qualified Data Types,
abbreviated to Liquid Types.
DSOLVE is an early application of liquid type inference in OCAML~\citep{liquid}.
A type-checking algorithm, which relies on an SMT solver
to compute subtyping efficiently for a core, first-order functional language
enhanced with refinement types~\citep{semanticSMT}, provides a different
approach.
LiquidHaskell~\citep{refHaskell} is a static verifier of
Haskell based on Liquid Types via SMT and predicate
abstraction.
DependentJS~\citep{dependentJS} incorporates dependent types into JavaScript. We note alsl, that HM(X) is a family of constraint-based type
systems~\citep{odersky99,pottier05}, that fits our formulation of the logical constraints.

A line of research closely related to our work concerns
the specific problem of predicting a TypeScript declaration file for an underlying JavaScript library. Writing and maintaining a declaration file is a non-trivial process. Both TSCHECK~\cite{feldthaus14} and TSTEST~\cite{kristensen17} demonstrates the difficult of the task, by detecting numerous errors in the declaration files of most of the libraries they have checked. \cite{tstools17} created the TSINFER and TSEVOLVE tools to that to assist the 
programmer for creating and maintaining TypeScript declaration files from JavaScript files. These tools are based on a combination of a static and dynamic analysis that uses a recorded snapshot of a concretely initialised library to generate TypeScript declaration files from JavaScript libraries. Dynamic analysis for TypeScript could serve as a different
source of information in our type inference framework. We
could capture results from dynamic analysis by adding a new term to our objective\eqref{eq:objective}.

 
\subsection{Soft Logic}\label{ssec:softlogic}
Recently, there is a resurgence of interest for \textit{soft logic} in the context of machine learning. By soft, logic we mean a many-valued logic, where the truth values lie on the unit interval $[0,1]$. The 
reason for this resurgence is twofold: First,
soft logic allows the modelling of multiple notions
of similarity. Second, and more relevant for our
interests, the resulting compound formulas are 
amenable to continuous optimisation approaches. Thus, they provide a framework to exploit the relational structure of different problems~\cite{kimmig12}.

In the context of \textit{fuzzy logic}, the three most
important extensions are G{\"o}del logic, {\L}ukasiewicz logic, and product logic~\cite{hajek98}, with the latter two attracting more interest. For example, the {\L}ukasiewicz logic is used in \citet{bach17} due 
to its convenient relationship with their relaxed MAX-SAT problem formulation. In our case, the relationships expressed by the logical constraints are non-convex, and we focus on smooth optimisation formulations; the product logic is more
suitable since the other two are non-smooth and 
would require relaxations. For 
deep learning, this logic is also important as it 
allows backpropagation~\cite{evans18}.

\subsection{Probabilistic Type Inference}\label{sec:ml:over:source}

Although the interdisciplinary field between machine learning and programming
languages is still young, complete reviews of this area are
already available.
\citet{vechev16} give a detailed description of the area.
\citet{threepillars}'s position paper examines this research area by categorising
the challenges involved in three main, overlapping pillars: intention, invention, and adaptation.
\citet{allamanis17} extensively survey work that probabilistically models source code via a learning component and complex representations of the underlying code.

A sub-field of this emerging area applies machine learning in probabilistic graphical models to infer semantic properties of programs, such as types.
The first example of this class
of approach was
JSNice~\citep{raychev15}, which uses probabilistic graphical models to infer types (and deobfuscate names) for JavaScript files. 
They use conditional random fields (CRF)~\cite{sutton12}, to encode variable relations between types, but not type constraints. 
\projectname differs from JSNice in incorporating logical type constraints and reformulating  probabilistic type inference as an optimisation problem.
\citet{xu16} use a different  graphical model to statistically infer types for Python. 
Their method trains a
classifier for each project that predicts the
type of each variable from its name.
The classifier's predictions for each variable are combined with semantic constraints using a kind of graphical model called a \emph{factor graph}~\citep{yedidia2003}, which is
closely related to CRFs.
To build their factor graph, they leverage type hints
derived from data flow, attribute accesses, subtyping, and naming conventions. Compared to our work,~\citet{xu16} require
heuristically chosen weights in the factors that integrate naming and semantic constraints; these heuristics may need to be tuned separately for each new kind of semantic constraint that is added to the model. In contrast, our method relies on an optimisation that integrates semantic constraints
and naming constraints in a principled way.
An important advantage of our approach
is that we can introduce type constraints from any standard type inference engine by automatically relaxing them.

% todo: deep approaches
Most recent works have used deep learning approaches to tackle
the problem of probabilistic type inference.
\cite{hellendoorn18} were the first to do so, by building 
DeepTyper, a tool that infers types for partially typed TypeScript code. DeepTyper uses a bidirectional neural network that leverages local lexical information to make type predictions for every identifier but otherwise ignores type constraints. 
A strength of DeepTyper is that it can handle a very large type vocabulary that spans both library and user-defined types.
NL2Type, a tool by~\cite{malik19}, also takes
a deep learning approach to the task, using JSDoc comments as an additional type hint.
Our approach differs from DeepTyper and NL2Type in  incorporating logical type constraints.
Our reformulation of probabilistic type inference as an optimisation problem that incorporates explicitly logical constraints separates us from these two approaches.

LambdaNet~\citep{wei20} was the first to apply a \emph{graph neural network} (GNN) model~\citep{Gilmer2017-qd,allamanis17a} to the probabilistic type inference task.
LambdaNet targets TypeScript and uses static analysis to build its GNN from the training data. 
This GNN combines logical and contextual (which subsumes \projectname's natural) constraints.
They are the first to be able to predict \emph{unseen} user-defined types by using a pointer-network-like architecture~\citep{vinyals15,Allamanis2016-su} to predict over an open vocabulary.
Typilus~\citep{allamanis20} is a GNN that employs one-shot learning to predict an open vocabulary of types, including rare and unseen user-defined types, for Python. 
Interestingly, both of these GNN models use an iterative
computation called message-passing to compute predictions,
which is closely related to the sum-product algorithm
used for inference in~\cite{xu16}, which also relies on message passing.
The main difference between our method and these two GNN-based approaches is that we do not learn the logical constraints but rather extracts and enforces them at test time.
Incorporating previously known, hard constraints into a learning
model is an effective way to improve its overall performance, but it does not imply that the result will respect them. What our approach does instead, is to offer a principled way to explicitly impose the logical constraints while constructively, 
and only at the places where is needed, absorbing information from the natural channel. In that sense, our work is complementary to each prior work above, as the described tools output
a probability vector over types, which our approach can take as its input to the
\textit{natural} part of our combined optimisation equation \eqref{eq:objective}.

\section{Conclusion}\label{sec:conclusion}

This paper addresses the lack of rich type inference process for dynamically typed languages.
To tackle this, we combine \textit{logical} constraints, deterministic information from a type system, with \textit{natural} constraints, uncertain information about types, learnt by machine learning techniques, while focusing on the satisfaction of the typing rules dictated by the language.
A core aim of our method is to guide the predictions from the learning procedure to respect the logical constraints.
We achieve this by relaxing the logical type inference problem into a continuous space.
%
This allows us to combine constructively the natural and logical part in a single optimisation problem with guaranteed constraint satisfaction. 
% To do this, we define a new probabilistic type inference procedure that combines
% programming language and machine learning techniques into a single framework.
%  we define a principled probabilistic framework that combines information from traditional analyses with statistical reasoning for source code in a single optimisation problem.
% Our framework combines  and constraints in 
% To achieve this, we relax the \textit{Logical} constraints to a continuous space representation.
% This enables as to embed them as hard constraint in the optimisation problem.
% Its predictions are guaranteed to obey the logical constraints while still leveraging uncertain information from the natural constraints, when they do not conflict with the logical constraints.
Our framework is extensible: it can incorporate arbitrary models information from the natural part and type constraints generated by traditional deterministic type inference systems.
% It reformulates probabilistic type inference as an optimisation problem.
We evaluate our framework by implementing \projectname{}, a tool that predicts types for TypeScript.
Our experiments show that \projectname{} achieves an accuracy of 74\% for the top-one prediction, marginally improving on state-of-the-art performance.
Our main insight is that instead of learning type inference rules as logical relationships we impose them as hard constraints and jointly optimise them with soft constraints coming from channels that carry type hints about the prediction.
Moreover, our principle of optimising logical and natural constraints together at test-time better guarantees that our predictions are type-correct.


% In practice, we have found that \projectname{}'s predictions satisfy our logical constraints; in future work we aim to develop some theoretical guarantees for our framework.


% Our method achieves numeric performance that is somewhat better than LambdaNet.

%We present a general probabilistic type inference framework that constructively combines different channels of information using numerical methods, while at the same time guarantees to preserve typing inference rules of the language as hard constraints in an optimisation problem. 

%Doing so one can literally achieve the best of both the dynamically and statically-typed worlds.
%% Acknowledgments
%\begin{acks}        
%% acks environment is optional
%% contents suppressed with 'anonymous'
%% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
%% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
%% acknowledge financial support and will be used by metadata
%% extraction tools.
%This material is based upon work supported by the
%\grantsponsor{GS100000001}{National Science
%Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
%No.~\grantnum{GS100000001}{nnnnnnn} and Grant
%No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
%conclusions or recommendations expressed in this material are those
%of the author and do not necessarily reflect the views of the
%National Science Foundation.
%\end{acks}

%% Bibliography
%\bibliographystyle{natbib}
\citestyle{acmnumeric}
\balance
\bibliography{references}

% %% Acknowledgments
% \begin{acks}                            %% acks environment is optional
%                                         %% contents suppressed with 'anonymous'
%   %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
%   %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
%   %% acknowledge financial support and will be used by metadata
%   %% extraction tools.
%   This material is based upon work supported by the
%   \grantsponsor{GS100000001}{National Science
%     Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
%   No.~\grantnum{GS100000001}{nnnnnnn} and Grant
%   No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
%   conclusions or recommendations expressed in this material are those
%   of the author and do not necessarily reflect the views of the
%   National Science Foundation.
% \end{acks}

%% Appendix
\appendix
\section{Appendix: Continuous Relaxation in the Logit Space}\label{app:appendix-logit}

In \cref{ssec:logcon}, we present the continuous interpretation based on probabilities.
As already mentioned, in the actual implementation we use logit instead for numerical stability.
The \emph{logit} of a probability is the logarithm of the odds ratio.
It is defined as the inverse of the softmax function; that is, an element of a probability vector $p \in [0,1]$ corresponds to
\begin{equation*}
	\pi = \log \frac{p}{1 - p}.
\end{equation*}
It allows us to map probability values from $\left[ 0, 1 \right]$ to $\left[ -\infty, \infty \right]$.

Given the matrix~$\mathcal{L}$, which corresponds to the logit of the matrix~$P$ in \cref{ssec:logcon}, we interpret an expression~$E$ as a number~$\qqpi{P}{E} \in \mathbb{R}$ as  follows:
%\ivp{Mention explicitly that this formulation maps scalar from [0,1] to [0,1], that is probability vectors do not require some extra form of scaling}
\begin{align*}
	\qqpi{\mathcal{L}}{x_v \mathrel{is} l_\tau} & = \pi_{v,\tau}                                                \\ \label{eq:logits}
	\qqpi{\mathcal{L}}{\mathrel{not} E}         & = \log(1-\text{sigmoid}(\qqpi{\mathcal{L}}{E})                \\
	\qqpi{\mathcal{L}}{E_1 \mathrel{and} E_2}   & = \qqpi{\mathcal{L}}{E_1} \mathrel{+} \qqpi{\mathcal{L}}{E_2} \\
	\qqpi{\mathcal{L}}{E_1 \mathrel{or} E_2}    & = \text{LogSumExp}(
	\qqpi{\mathcal{L}}{E_1} + \qqpi{\mathcal{L}}{E_2} - \qqpi{\mathcal{L}}{E_1} \cdot \qqpi{\mathcal{L}}{E_2}).
\end{align*}
The sigmoid function is defined as
\begin{equation*}
	\text{sigmoid}(a) = \frac{\exp\{a\}}{1 + \exp\{a\}},
\end{equation*}
while the LogSumExp function is defined as
\begin{equation*}
	\text{LogSumExp}(\bm{x}) = \log\left( \sum_i \exp\{x_i\} \right).
\end{equation*}

\section{Appendix: Formal Proofs}\label{app:proofs}
\subsection{Proofs for Logical Constraints}


\begin{lemma} \label{lem:binary}
    For all $E$ and $\Gamma$, $\qqpi{B(\Gamma)}{E} \in \{0,1\}$.
\end{lemma}

\begin{proof} %\label{cor:binary}
    By structural induction on the continuous semantics.
\end{proof}


\begin{lemma}
For all $E$, $E_1$, $E_2$, and $\Gamma$:
\begin{enumerate}
    \item $\qqpi{B(\Gamma)}{E} = 0 \Leftrightarrow{} not (\qqpi{B(\Gamma)}{E} = 1)$
    \item $\qqpi{B(\Gamma)}{E_1} = 1 \mathrel{and} \qqpi{B(\Gamma)}{E_2} = 1 \Leftrightarrow{}  \qqpi{B(\Gamma)}{E_1} \cdot \qqpi{B(\Gamma)}{E_2} = 1$
    \item $\qqpi{B(\Gamma)}{E_1} = 1 \mathrel{or} \qqpi{B(\Gamma)}{E_2} = 1 \Leftrightarrow{}  \qqpi{B(\Gamma)}{E_1} + \qqpi{B(\Gamma)}{E_2} - \qqpi{B(\Gamma)}{E_1} \cdot \qqpi{B(\Gamma)}{E_2} = 1$
\end{enumerate}
\end{lemma}
\begin{proof}
  These follow by cases analyses based on Lemma~\ref{lem:binary}.
\end{proof}


\begin{lemma} \label{lem:models}
    For all $E$ and $\Gamma$, either $\Gamma \models E$ or $\Gamma \models{} \mathrel{not} E$.
\end{lemma}

\begin{proof}
    By structural induction on the satisfaction relation.
\end{proof}

% \begin{cor}
% As a corollary of Lemma 2.2, we can state that
% $\qqpi{B(\Gamma)}{E} = 0 \Leftrightarrow{} not (\Gamma \models{} E$. 
% \end{cor}

% Irene: explain why this theorem corresponds to the result in the book?


\restate{Theorem~\ref{thm:soft2hard}} For all $E$ and $\Gamma$: $\qqpi{B(\Gamma)}{E} = 1 \Leftrightarrow \Gamma \models E$.
\begin{proof}
  We prove the property by \emph{structural induction}; that is,
  we prove that $\phi(N)$ holds for all $N$, where $\phi(N)$ is as follows.
        %\begin{quote}
        \begin{equation*}
            \phi(N) \triangleq
                \forall E, \forall \Gamma :
                size(E)=N \Rightarrow (\Gamma \models E \Leftrightarrow \qqpi{B(\Gamma)}{E} = 1).
        \end{equation*}
        %\end{quote}
        
  We proceed by course-of-values induction on $N$.
  Consider any $E, \Gamma$ and $N = size(E)$. We proceed by a case analysis at $E$.
  \begin{description}
      \item[$Base\;Case$]
                  For $N=1$, the base case is $E = (x_v \mathrel{is} l_\tau)$.
                  For any $\Gamma$ we are to show
                  \begin{equation*}
                  \Gamma \models x_v \mathrel{is} l_\tau \Leftrightarrow{}\qqpi{B(\Gamma)}{x_v \mathrel{is} l_\tau} = 1.
                  \end{equation*}
                  
                  By definition, $\qqpi{B(\Gamma)}{x_v \mathrel{is} l_\tau} = p_{v,\tau}$
                  where $p_{v,\tau}$ is the probability that variable $x_v$ has type $l_\tau$ according to the matrix $B(\Gamma)$. 
                  By definition of $B(\Gamma)$ and because $B$ results to  a binary matrix,  
                  $\qqpi{B(\Gamma)}{x_v \mathrel{is} l_\tau} = 1$
                  means that the element $p_{v,\tau}$ is equal to $1$, that is 
                  $\Gamma \models x_v \mathrel{is} l_\tau$.
                  Also, $\Gamma \models x_v \mathrel{is} l_\tau$, implies that $\Gamma(x_v)=l_\tau$. By definition, that
                  means  $\qqpi{B(\Gamma)}{x_v \mathrel{is} l_\tau} = 1$.
      
     \item[$Case \; E ={} \mathrel{not} E'$.]
                  We are to show
                  $\Gamma \models{} \mathrel{not} E' \Leftrightarrow \qqpi{B(\Gamma)}{\mathrel{not} E'} = 1$.
                  We have that,
                  \begin{align*}
%                       \Gamma \models{} \mathrel{not} E' \Leftrightarrow{} & \mathrel{not}  \Gamma \models{}  E'  \\
                        \qqpi{B(\Gamma)}{\mathrel{not} E'} = 1 & \Leftrightarrow{} &  \\
                        1- \qqpi{B(\Gamma)}{E'} = 1 & \Leftrightarrow{} & \text{(Definition)}  \\
                        \qqpi{B(\Gamma)}{E'} = 0 & \Leftrightarrow{} &  \\
                        \mathrel{not} (\qqpi{B(\Gamma)}{E'} = 1) & \Leftrightarrow{} & \text{(Lemma~\ref{lem:binary})} \\
                        \mathrel{not}  \Gamma \models{}  E'
                        & \Leftrightarrow{} & \text{(Induction Hypothesis)} \\
                         \Gamma \models{} \mathrel{not} E' & & \text{(Definition)}.
                  \end{align*}
          
          \item[$Case \; E = (E_1 \mathrel{and} E_2)$.] 
                  For $size(E_1)<N$ and $size(E_2) < N$, we are to show that
                  $\Gamma \models (E_1 \mathrel{and} E_2) \Leftrightarrow \qqpi{B(\Gamma)}{(E_1 \mathrel{and} E_2)} = 1$. Our induction hypothesis is that $\phi(M)$ holds for all $M<N$. We have that
                  \begin{align*}
                      \Gamma \models (E_1 \mathrel{and} E_2)                            & \Leftrightarrow &  \\
                      \Gamma \models E_1 \mathrel{and} \Gamma \models E_2               & \Leftrightarrow & \text{(Definition)}  \\
                      \qqpi{B(\Gamma)}{E_1} = 1 \mathrel{and} \qqpi{B(\Gamma)}{E_2} = 1 & \Leftrightarrow & \text{(Induction Hypothesis)}           \\
                      \qqpi{B(\Gamma)}{E_1} \cdot \qqpi{B(\Gamma)}{E_2} = 1             & \Leftrightarrow &  \text{(Lemma~\ref{lem:binary})}           \\                 
                      \qqpi{B(\Gamma)}{(E_1 \mathrel{and} E_2)} = 1                  &   &  \text{(Definition)}                                         \\
                  \end{align*}
                  which completes the proof for this case.

            \item[$Case \; E = (E_1 \mathrel{or} E_2)$.]
                  For $size(E_1) < N$ and $size(E_2) < N$, we are to show
                  $\Gamma \models (E_1 \mathrel{and} E_2) \Leftrightarrow \qqpi{B(\Gamma)}{(E_1 \mathrel{and} E_2)} = 1$. Our induction hypothesis is that $\phi(M)$ holds for all $M<N$. We have that
                  \begin{align*}
                      \Gamma \models (E_1 \mathrel{or} E_2)                                                                     & \Leftrightarrow & \\
                      \Gamma \models E_1 \mathrel{or} \Gamma \models E_2                                                        & \Leftrightarrow &\text{(Definition)} \\
                      \qqpi{B(\Gamma)}{E_1} = 1 \mathrel{or} \qqpi{B(\Gamma)}{E_2} = 1                                          & \Leftrightarrow & \text{(Induction Hypothesis)}                                  \\
                      (\qqpi{B(\Gamma)}{E_1} - 1) \cdot (1- \qqpi{B(\Gamma)}{E_2}) = 0                                          & \Leftrightarrow                                  \\
                      \qqpi{B(\Gamma)}{E_1} - \qqpi{B(\Gamma)}{E_1} \cdot \qqpi{B(\Gamma)}{E_2} + \qqpi{B(\Gamma)}{E_2} - 1 = 0 & \Leftrightarrow                         &\text{(Case Analysis \& Lemma~\ref{lem:binary})}         \\
                      \qqpi{B(\Gamma)}{E_1 \mathrel{or} E_2} = 1                                                               &. 
                  \end{align*}
                  which completes the proof for this case.
    \end{description}
\end{proof}


% \begin{lemma}\label{lem:bounds}
%     For all $E$ and for all $P \in [0, 1]^{V \times T}$,  then $0 \leq \qqpi{P}{E} \leq 1$.
% \end{lemma}
% \begin{proof}
%     By structural induction on the expression $E$.
% \end{proof}


% \begin{lemma} \label{thm:soft2hard_v2}
%     For all $E$, and all type environments $\Gamma$,
%     then if not $\Gamma \models E$, then
%     $\qqpi{B(\Gamma)}{E} = 0$.
% \end{lemma}

% \begin{proof}
%     This is a corollary of Claim 2.1. If not $\Gamma \models E$,  then $\Gamma \models{} \mathrel{not} E$, by the logical satisfaction relation. Then, by Lemma~\ref{lem:binary},
%     $\qqpi{B(\Gamma)}{\mathrel{not} E} = 1$.
%     By the definition of continuous semantics,
%     $\qqpi{B(\Gamma)}{\mathrel{not} E} = 1 - \qqpi{B(\Gamma)}{E}$.
% \end{proof}


% \begin{lemma}\label{lem:positive}
% For all $E$,
% $$\max_{P \in \Pi^{V \times T}} \qqpi{P}{E} > 0.$$
% \end{lemma}
% %\cascomment{I am not assuming that $P = B(\Gamma)$ for some $\Gamma$.}
% \begin{proof}
% For all matrices $Q  \in \Pi^{V \times T}$, we have
% \begin{align}
% \textstyle \max_{P \in \Pi^{V \times T}} \qqpi{P}{E} > \qqpi{Q}{E}.
% \end{align}
% Choose $Q \in \Pi^{V \times T}$ such as $q_{v,t} = 1/T$ for all $v \in 1 \ldots V$ and $t \in 1 \ldots T$. We proceed by course-of-value induction on N.  Consider any $E, P$ and $N = size(E)$. The proof completes by course-of-values induction on $N$.

% \end{proof}

% \restate{Theorem~\ref{thm:argmax}} For all $\Gamma$ and all $E$,
% $\Gamma \models E$
% if and only if $B(\Gamma) \in \arg\max_{P \in \Pi^{V \times T}} \qqpi{P}{E}$.

% \begin{proof}
% Consider any $\Gamma$ and $E$.
% Either $\Gamma \models E$ or not.

% If $\Gamma \models E$ then the theorem follows as a simple consequence of Theorem~\ref{thm:soft2hard}.

% Otherwise both sides of the biconditional are always false:
% $\Gamma \models E$ is false by assumption,
% and $B(\Gamma) \in \arg\max_{P \in \Pi^{V \times T}} \qqpi{P}{E}$
% is false by Lemma~\ref{lem:positive}. (We can show that $\qqpi{B(\Gamma)}{E} = 0$ by considering that $\qqpi{B(\Gamma)}{\mathrel{not} E} = 1$.) So the biconditional is trivially true.
% \end{proof}


\section{Appendix: Neural Model }\label{app:neural} 
In this appendix we present the implementation details of the deep neural  used in \cref{ssec:natprodts}.
\begin{lstlisting}[numbers=none,caption={Our Character Level \textit{LSTM} model.},captionpos=b]
  LSTMClassifier(
  (embedding): Embedding(90, 128)
  (lstm): LSTM(128, 64)
  (hidden2out): Linear(in_features=64, 
                out_features=100, bias=True)
  (softmax): LogSoftmax()
  (optimization fun): ADAM)
\end{lstlisting}

\end{document}
